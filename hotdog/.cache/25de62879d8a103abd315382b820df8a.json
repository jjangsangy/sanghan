{"dependencies":[{"name":"/Users/sanghan/Desktop/tfjs-examples/mobilenet/package.json","includedInParent":true,"mtime":1522644996454},{"name":"/Users/sanghan/Desktop/tfjs-examples/mobilenet/node_modules/@tensorflow/tfjs-core/package.json","includedInParent":true,"mtime":0},{"name":"seedrandom","loc":{"line":38,"column":25}},{"name":"../environment","loc":{"line":39,"column":28}},{"name":"../ops/axis_util","loc":{"line":40,"column":24}},{"name":"../ops/broadcast_util","loc":{"line":41,"column":29}},{"name":"../ops/concat_util","loc":{"line":42,"column":26}},{"name":"../ops/ops","loc":{"line":44,"column":20}},{"name":"../ops/selu_util","loc":{"line":45,"column":24}},{"name":"../tensor","loc":{"line":46,"column":23}},{"name":"../types","loc":{"line":47,"column":20}},{"name":"../util","loc":{"line":48,"column":19}},{"name":"./backend_util","loc":{"line":49,"column":27}}],"generated":{"js":"\"use strict\";\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = y[op[0] & 2 ? \"return\" : op[0] ? \"throw\" : \"next\"]) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [0, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar seedrandom = require(\"seedrandom\");\nvar environment_1 = require(\"../environment\");\nvar axis_util = require(\"../ops/axis_util\");\nvar broadcast_util = require(\"../ops/broadcast_util\");\nvar concat_util = require(\"../ops/concat_util\");\nvar ops = require(\"../ops/ops\");\nvar ops_1 = require(\"../ops/ops\");\nvar selu_util = require(\"../ops/selu_util\");\nvar tensor_1 = require(\"../tensor\");\nvar types = require(\"../types\");\nvar util = require(\"../util\");\nvar backend_util = require(\"./backend_util\");\nvar MathBackendCPU = (function () {\n    function MathBackendCPU() {\n        this.data = new WeakMap();\n        if (typeof document !== 'undefined') {\n            this.canvas = document.createElement('canvas');\n        }\n    }\n    MathBackendCPU.prototype.register = function (dataId, shape, dtype) {\n        if (this.data.has(dataId)) {\n            throw new Error(\"Data buffer is already registered\");\n        }\n        this.data.set(dataId, null);\n    };\n    MathBackendCPU.prototype.write = function (dataId, values) {\n        if (values == null) {\n            throw new Error('MathBackendCPU.write(): values can not be null');\n        }\n        this.throwIfNoData(dataId);\n        this.data.set(dataId, values);\n    };\n    MathBackendCPU.prototype.fromPixels = function (pixels, numChannels) {\n        if (pixels == null) {\n            throw new Error('MathBackendCPU.writePixels(): pixels can not be null');\n        }\n        var vals;\n        if (pixels instanceof ImageData) {\n            vals = pixels.data;\n        }\n        else if (pixels instanceof HTMLCanvasElement) {\n            vals = pixels.getContext('2d')\n                .getImageData(0, 0, pixels.width, pixels.height)\n                .data;\n        }\n        else if (pixels instanceof HTMLImageElement ||\n            pixels instanceof HTMLVideoElement) {\n            if (this.canvas == null) {\n                throw new Error('Can\\'t read pixels from HTMLImageElement outside ' +\n                    'the browser.');\n            }\n            this.canvas.width = pixels.width;\n            this.canvas.height = pixels.height;\n            this.canvas.getContext('2d').drawImage(pixels, 0, 0, pixels.width, pixels.height);\n            vals = this.canvas.getContext('2d')\n                .getImageData(0, 0, pixels.width, pixels.height)\n                .data;\n        }\n        else {\n            throw new Error(\"pixels is of unknown type: \" + pixels.constructor.name);\n        }\n        var values;\n        if (numChannels === 4) {\n            values = new Int32Array(vals);\n        }\n        else {\n            var numPixels = pixels.width * pixels.height;\n            values = new Int32Array(numPixels * numChannels);\n            for (var i = 0; i < numPixels; i++) {\n                for (var channel = 0; channel < numChannels; ++channel) {\n                    values[i * numChannels + channel] = vals[i * 4 + channel];\n                }\n            }\n        }\n        var outShape = [pixels.height, pixels.width, numChannels];\n        return ops_1.tensor3d(values, outShape, 'int32');\n    };\n    MathBackendCPU.prototype.read = function (dataId) {\n        return __awaiter(this, void 0, void 0, function () {\n            return __generator(this, function (_a) {\n                return [2, this.readSync(dataId)];\n            });\n        });\n    };\n    MathBackendCPU.prototype.readSync = function (dataId) {\n        this.throwIfNoData(dataId);\n        return this.data.get(dataId);\n    };\n    MathBackendCPU.prototype.disposeData = function (dataId) {\n        if (this.data.has(dataId)) {\n            this.data.delete(dataId);\n        }\n    };\n    MathBackendCPU.prototype.time = function (f) {\n        return __awaiter(this, void 0, void 0, function () {\n            var start, kernelMs;\n            return __generator(this, function (_a) {\n                start = performance.now();\n                f();\n                kernelMs = performance.now() - start;\n                return [2, { kernelMs: kernelMs }];\n            });\n        });\n    };\n    MathBackendCPU.prototype.memory = function () {\n        return {\n            unreliable: true\n        };\n    };\n    MathBackendCPU.prototype.throwIfNoData = function (dataId) {\n        if (!this.data.has(dataId)) {\n            throw new Error(\"CPU backend: No data found for this tensor. \" +\n                \"Did you change your backend in the middle of the program? \" +\n                \"New backends can't use Tensors created with previous backends\");\n        }\n    };\n    MathBackendCPU.prototype.slice = function (x, begin, size) {\n        var buffer = ops.buffer(size, x.dtype);\n        for (var i = 0; i < buffer.size; ++i) {\n            var loc = buffer.indexToLoc(i);\n            var xLoc = loc.map(function (idx, j) { return idx + begin[j]; });\n            buffer.set.apply(buffer, [x.get.apply(x, xLoc)].concat(loc));\n        }\n        return buffer.toTensor();\n    };\n    MathBackendCPU.prototype.reverse = function (x, axis) {\n        var buffer = ops.buffer(x.shape, x.dtype);\n        var xBuffer = x.buffer();\n        var _loop_1 = function (i) {\n            var outLoc = buffer.indexToLoc(i);\n            var inLoc = outLoc.slice();\n            axis.forEach(function (ax) { return inLoc[ax] = x.shape[ax] - 1 - inLoc[ax]; });\n            buffer.set.apply(buffer, [xBuffer.get.apply(xBuffer, inLoc)].concat(outLoc));\n        };\n        for (var i = 0; i < buffer.size; i++) {\n            _loop_1(i);\n        }\n        return buffer.toTensor();\n    };\n    MathBackendCPU.prototype.concat = function (a, b) {\n        var outShape = concat_util.computeOutShape(a.shape, b.shape, 1);\n        var buffer = ops.buffer(outShape, a.dtype);\n        if (a.shape[0] === 1 && b.shape[0] === 1) {\n            var aVals = a.dataSync();\n            var bVals = b.dataSync();\n            var vals = buffer.values;\n            vals.set(aVals, 0);\n            vals.set(bVals, a.size);\n            return buffer.toTensor();\n        }\n        for (var i = 0; i < outShape[0]; ++i) {\n            for (var j = 0; j < a.shape[1]; ++j) {\n                buffer.set(a.get(i, j), i, j);\n            }\n            for (var j = 0; j < b.shape[1]; ++j) {\n                buffer.set(b.get(i, j), i, j + a.shape[1]);\n            }\n        }\n        return buffer.toTensor();\n    };\n    MathBackendCPU.prototype.neg = function (x) {\n        return this.multiply(ops.scalar(-1), x);\n    };\n    MathBackendCPU.prototype.add = function (a, b) {\n        return this.broadcastedBinaryOp(a, b, types.upcastType(a.dtype, b.dtype), function (aValue, bValue) { return aValue + bValue; });\n    };\n    MathBackendCPU.prototype.subtract = function (a, b) {\n        return this.broadcastedBinaryOp(a, b, types.upcastType(a.dtype, b.dtype), function (aValue, bValue) { return aValue - bValue; });\n    };\n    MathBackendCPU.prototype.pow = function (a, b) {\n        return this.broadcastedBinaryOp(a, b, a.dtype, function (aValue, bValue) { return Math.pow(aValue, bValue); });\n    };\n    MathBackendCPU.prototype.matMul = function (a, b, transposeA, transposeB) {\n        var sharedDim = transposeA ? a.shape[0] : a.shape[1];\n        var leftDim = transposeA ? a.shape[1] : a.shape[0];\n        var rightDim = transposeB ? b.shape[0] : b.shape[1];\n        var normalGetter = function (matrix, i, j) {\n            return matrix.get(i, j);\n        };\n        var transposedGetter = function (matrix, i, j) {\n            return matrix.get(j, i);\n        };\n        var aGetter = transposeA ? transposedGetter : normalGetter;\n        var bGetter = transposeB ? transposedGetter : normalGetter;\n        var values = new Float32Array(leftDim * rightDim);\n        var index = 0;\n        for (var i = 0; i < leftDim; ++i) {\n            for (var j = 0; j < rightDim; ++j) {\n                var sum = 0;\n                for (var k = 0; k < sharedDim; ++k) {\n                    sum += aGetter(a, i, k) * bGetter(b, k, j);\n                }\n                values[index++] = sum;\n            }\n        }\n        return ops.tensor2d(values, [leftDim, rightDim]);\n    };\n    MathBackendCPU.prototype.multiply = function (a, b) {\n        return this.broadcastedBinaryOp(a, b, types.upcastType(a.dtype, b.dtype), function (aValue, bValue) { return aValue * bValue; });\n    };\n    MathBackendCPU.prototype.divide = function (a, b) {\n        return this.broadcastedBinaryOp(a, b, 'float32', function (aValue, bValue) { return aValue / bValue; });\n    };\n    MathBackendCPU.prototype.sum = function (x, axes) {\n        axis_util.assertAxesAreInnerMostDims('sum', axes, x.rank);\n        var _a = axis_util.computeOutAndReduceShapes(x.shape, axes), outShape = _a[0], reduceShape = _a[1];\n        var resultDtype = types.upcastType(x.dtype, 'int32');\n        var result = ops.zeros(outShape, resultDtype);\n        var reduceSize = util.sizeFromShape(reduceShape);\n        var vals = result.dataSync();\n        var aVals = x.dataSync();\n        for (var i = 0; i < vals.length; ++i) {\n            var offset = i * reduceSize;\n            var sum = 0;\n            for (var j = 0; j < reduceSize; ++j) {\n                sum += aVals[offset + j];\n            }\n            vals[i] = sum;\n        }\n        return result;\n    };\n    MathBackendCPU.prototype.argMin = function (x, axes) {\n        axis_util.assertAxesAreInnerMostDims('argMin', axes, x.rank);\n        var _a = axis_util.computeOutAndReduceShapes(x.shape, axes), outShape = _a[0], reduceShape = _a[1];\n        var result = ops.zeros(outShape, 'int32');\n        var reduceSize = util.sizeFromShape(reduceShape);\n        var vals = result.dataSync();\n        var aVals = x.dataSync();\n        for (var i = 0; i < vals.length; ++i) {\n            var offset = i * reduceSize;\n            var min = aVals[offset];\n            var minIndex = 0;\n            for (var j = 0; j < reduceSize; ++j) {\n                var value = aVals[offset + j];\n                if (isNaN(value)) {\n                    minIndex = util.NAN_INT32;\n                    break;\n                }\n                if (value < min) {\n                    min = value;\n                    minIndex = j;\n                }\n            }\n            vals[i] = minIndex;\n        }\n        return result;\n    };\n    MathBackendCPU.prototype.argMax = function (x, axes) {\n        axis_util.assertAxesAreInnerMostDims('argMax', axes, x.rank);\n        var _a = axis_util.computeOutAndReduceShapes(x.shape, axes), outShape = _a[0], reduceShape = _a[1];\n        var result = ops.zeros(outShape, 'int32');\n        var reduceSize = util.sizeFromShape(reduceShape);\n        var vals = result.dataSync();\n        var aVals = x.dataSync();\n        for (var i = 0; i < vals.length; ++i) {\n            var offset = i * reduceSize;\n            var max = aVals[offset];\n            var maxIndex = 0;\n            for (var j = 0; j < reduceSize; ++j) {\n                var value = aVals[offset + j];\n                if (isNaN(value)) {\n                    maxIndex = util.NAN_INT32;\n                    break;\n                }\n                if (value > max) {\n                    max = value;\n                    maxIndex = j;\n                }\n            }\n            vals[i] = maxIndex;\n        }\n        return result;\n    };\n    MathBackendCPU.prototype.equal = function (a, b) {\n        return this.broadcastedBinaryOp(a, b, 'bool', function (aVal, bVal) {\n            if (util.isValNaN(aVal, a.dtype) || util.isValNaN(bVal, b.dtype)) {\n                return util.getNaN('bool');\n            }\n            else {\n                return (aVal === bVal) ? 1 : 0;\n            }\n        });\n    };\n    MathBackendCPU.prototype.notEqual = function (a, b) {\n        return this.broadcastedBinaryOp(a, b, 'bool', function (aVal, bVal) {\n            if (util.isValNaN(aVal, a.dtype) || util.isValNaN(bVal, b.dtype)) {\n                return util.getNaN('bool');\n            }\n            else {\n                return (aVal !== bVal) ? 1 : 0;\n            }\n        });\n    };\n    MathBackendCPU.prototype.less = function (a, b) {\n        return this.broadcastedBinaryOp(a, b, 'bool', function (aVal, bVal) {\n            if (util.isValNaN(aVal, a.dtype) || util.isValNaN(bVal, b.dtype)) {\n                return util.getNaN('bool');\n            }\n            else {\n                return (aVal < bVal) ? 1 : 0;\n            }\n        });\n    };\n    MathBackendCPU.prototype.lessEqual = function (a, b) {\n        return this.broadcastedBinaryOp(a, b, 'bool', function (aVal, bVal) {\n            if (util.isValNaN(aVal, a.dtype) || util.isValNaN(bVal, b.dtype)) {\n                return util.getNaN('bool');\n            }\n            else {\n                return (aVal <= bVal) ? 1 : 0;\n            }\n        });\n    };\n    MathBackendCPU.prototype.greater = function (a, b) {\n        return this.broadcastedBinaryOp(a, b, 'bool', function (aVal, bVal) {\n            if (util.isValNaN(aVal, a.dtype) || util.isValNaN(bVal, b.dtype)) {\n                return util.getNaN('bool');\n            }\n            else {\n                return (aVal > bVal) ? 1 : 0;\n            }\n        });\n    };\n    MathBackendCPU.prototype.greaterEqual = function (a, b) {\n        return this.broadcastedBinaryOp(a, b, 'bool', function (aVal, bVal) {\n            if (util.isValNaN(aVal, a.dtype) || util.isValNaN(bVal, b.dtype)) {\n                return util.getNaN('bool');\n            }\n            else {\n                return (aVal >= bVal) ? 1 : 0;\n            }\n        });\n    };\n    MathBackendCPU.prototype.logicalNot = function (x) {\n        var values = x.dataSync();\n        var newValues = new Int32Array(values.length);\n        for (var i = 0; i < values.length; ++i) {\n            if (util.isValNaN(values[i], x.dtype)) {\n                newValues[i] = util.getNaN('bool');\n            }\n            else {\n                newValues[i] = values[i] ? 0 : 1;\n            }\n        }\n        return tensor_1.Tensor.make(x.shape, { values: newValues }, 'bool');\n    };\n    MathBackendCPU.prototype.logicalAnd = function (a, b) {\n        return this.broadcastedBinaryOp(a, b, 'bool', function (aVal, bVal) {\n            if (util.isValNaN(aVal, a.dtype) || util.isValNaN(bVal, b.dtype)) {\n                return util.getNaN('bool');\n            }\n            else {\n                return aVal && bVal;\n            }\n        });\n    };\n    MathBackendCPU.prototype.logicalOr = function (a, b) {\n        return this.broadcastedBinaryOp(a, b, 'bool', function (aVal, bVal) {\n            if (util.isValNaN(aVal, a.dtype) || util.isValNaN(bVal, b.dtype)) {\n                return util.getNaN('bool');\n            }\n            else {\n                return aVal || bVal;\n            }\n        });\n    };\n    MathBackendCPU.prototype.logicalXor = function (a, b) {\n        return this.broadcastedBinaryOp(a, b, 'bool', function (aVal, bVal) {\n            if (util.isValNaN(aVal, a.dtype) || util.isValNaN(bVal, b.dtype)) {\n                return util.getNaN('bool');\n            }\n            else {\n                return aVal ^ bVal;\n            }\n        });\n    };\n    MathBackendCPU.prototype.where = function (condition, a, b, dtype) {\n        var values = condition.dataSync();\n        var aValues = a.dataSync();\n        var bValues = b.dataSync();\n        var result = ops.zeros(a.shape, dtype);\n        var newValues = result.dataSync();\n        var index = 0;\n        var offset = condition.rank === 0 || condition.rank > 1 || a.rank === 1 ?\n            1 :\n            a.shape[1];\n        for (var i = 0; i < values.length; i++) {\n            for (var j = 0; j < offset; j++) {\n                if (values[i] === 1) {\n                    newValues[index++] = aValues[i];\n                }\n                else {\n                    newValues[index++] = bValues[i];\n                }\n            }\n        }\n        return result;\n    };\n    MathBackendCPU.prototype.topKValues = function (x, k) {\n        return this.topK(x, k).values;\n    };\n    MathBackendCPU.prototype.topKIndices = function (x, k) {\n        return this.topK(x, k).indices;\n    };\n    MathBackendCPU.prototype.topK = function (x, k) {\n        var values = x.dataSync();\n        var valuesAndIndices = [];\n        for (var i = 0; i < values.length; i++) {\n            valuesAndIndices.push({ value: values[i], index: i });\n        }\n        valuesAndIndices.sort(function (a, b) {\n            return b.value - a.value;\n        });\n        var topkValues = util.getTypedArrayFromDType(x.dtype, k);\n        var topkIndices = new Int32Array(k);\n        for (var i = 0; i < k; i++) {\n            topkValues[i] = valuesAndIndices[i].value;\n            topkIndices[i] = valuesAndIndices[i].index;\n        }\n        return {\n            values: ops.tensor1d(topkValues, x.dtype),\n            indices: ops.tensor1d(topkIndices, 'int32')\n        };\n    };\n    MathBackendCPU.prototype.min = function (x, axes) {\n        axis_util.assertAxesAreInnerMostDims('min', axes, x.rank);\n        var _a = axis_util.computeOutAndReduceShapes(x.shape, axes), outShape = _a[0], reduceShape = _a[1];\n        var result = ops.zeros(outShape, x.dtype);\n        var reduceSize = util.sizeFromShape(reduceShape);\n        var vals = result.dataSync();\n        var aVals = x.dataSync();\n        for (var i = 0; i < vals.length; ++i) {\n            var offset = i * reduceSize;\n            var min = aVals[0];\n            for (var j = 0; j < reduceSize; ++j) {\n                var value = aVals[offset + j];\n                if (isNaN(value)) {\n                    min = Number.NaN;\n                    break;\n                }\n                if (value < min) {\n                    min = value;\n                }\n            }\n            vals[i] = min;\n        }\n        return result;\n    };\n    MathBackendCPU.prototype.minimum = function (a, b) {\n        return this.broadcastedBinaryOp(a, b, a.dtype, function (aVal, bVal) { return Math.min(aVal, bVal); });\n    };\n    MathBackendCPU.prototype.max = function (x, axes) {\n        axis_util.assertAxesAreInnerMostDims('max', axes, x.rank);\n        var _a = axis_util.computeOutAndReduceShapes(x.shape, axes), outShape = _a[0], reduceShape = _a[1];\n        var result = ops.zeros(outShape, x.dtype);\n        var reduceSize = util.sizeFromShape(reduceShape);\n        var vals = result.dataSync();\n        var aVals = x.dataSync();\n        for (var i = 0; i < vals.length; ++i) {\n            var offset = i * reduceSize;\n            var max = aVals[offset];\n            for (var j = 0; j < reduceSize; ++j) {\n                var value = aVals[offset + j];\n                if (isNaN(value)) {\n                    max = Number.NaN;\n                    break;\n                }\n                if (value > max) {\n                    max = value;\n                }\n            }\n            vals[i] = max;\n        }\n        return result;\n    };\n    MathBackendCPU.prototype.maximum = function (a, b) {\n        return this.broadcastedBinaryOp(a, b, a.dtype, function (aVal, bVal) { return Math.max(aVal, bVal); });\n    };\n    MathBackendCPU.prototype.ceil = function (x) {\n        var values = x.dataSync();\n        var newValues = new Float32Array(values.length);\n        for (var i = 0; i < values.length; ++i) {\n            newValues[i] = Math.ceil(values[i]);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: newValues });\n    };\n    MathBackendCPU.prototype.floor = function (x) {\n        var values = x.dataSync();\n        var newValues = new Float32Array(values.length);\n        for (var i = 0; i < values.length; ++i) {\n            newValues[i] = Math.floor(values[i]);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: newValues });\n    };\n    MathBackendCPU.prototype.exp = function (x) {\n        var values = x.dataSync();\n        var newValues = new Float32Array(values.length);\n        for (var i = 0; i < values.length; ++i) {\n            newValues[i] = Math.exp(values[i]);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: newValues });\n    };\n    MathBackendCPU.prototype.log = function (x) {\n        var values = x.dataSync();\n        var newValues = new Float32Array(values.length);\n        for (var i = 0; i < values.length; ++i) {\n            var value = values[i];\n            newValues[i] = Math.log(value);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: newValues });\n    };\n    MathBackendCPU.prototype.log1p = function (x) {\n        var values = x.dataSync();\n        var newValues = new Float32Array(values.length);\n        for (var i = 0; i < values.length; ++i) {\n            var value = values[i];\n            newValues[i] = Math.log1p(value);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: newValues });\n    };\n    MathBackendCPU.prototype.sqrt = function (x) {\n        var values = x.dataSync();\n        var newValues = new Float32Array(values.length);\n        for (var i = 0; i < values.length; ++i) {\n            var value = values[i];\n            newValues[i] = Math.sqrt(value);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: newValues });\n    };\n    MathBackendCPU.prototype.square = function (x) {\n        var values = x.dataSync();\n        var newValues = new Float32Array(values.length);\n        for (var i = 0; i < values.length; ++i) {\n            var value = values[i];\n            newValues[i] = value * value;\n        }\n        return tensor_1.Tensor.make(x.shape, { values: newValues });\n    };\n    MathBackendCPU.prototype.relu = function (x) {\n        var res = ops.zeros(x.shape, x.dtype);\n        var resVals = res.dataSync();\n        var inVals = x.dataSync();\n        for (var i = 0; i < inVals.length; ++i) {\n            var val = inVals[i];\n            if (util.isValNaN(val, x.dtype)) {\n                resVals[i] = util.getNaN(res.dtype);\n            }\n            else {\n                resVals[i] = Math.max(0, inVals[i]);\n            }\n        }\n        return res;\n    };\n    MathBackendCPU.prototype.elu = function (x) {\n        var resultValues = new Float32Array(x.size);\n        var values = x.dataSync();\n        for (var i = 0; i < values.length; ++i) {\n            var v = values[i];\n            if (v >= 0) {\n                resultValues[i] = v;\n            }\n            else {\n                resultValues[i] = (Math.exp(v) - 1);\n            }\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.eluDer = function (x) {\n        var resultValues = new Float32Array(x.size);\n        var values = x.dataSync();\n        for (var i = 0; i < values.length; ++i) {\n            var v = values[i];\n            if (v >= 0) {\n                resultValues[i] = 1;\n            }\n            else {\n                resultValues[i] = Math.exp(v);\n            }\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.selu = function (x) {\n        var scaleAlpha = selu_util.SELU_SCALEALPHA;\n        var scale = selu_util.SELU_SCALE;\n        var resultValues = new Float32Array(x.size);\n        var values = x.dataSync();\n        for (var i = 0; i < values.length; ++i) {\n            var v = values[i];\n            if (v >= 0) {\n                resultValues[i] = scale * v;\n            }\n            else {\n                resultValues[i] = scaleAlpha * (Math.exp(v) - 1);\n            }\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.leakyRelu = function (x, alpha) {\n        var resultValues = new Float32Array(x.size);\n        var values = x.dataSync();\n        for (var i = 0; i < values.length; i++) {\n            var v = values[i];\n            if (v >= 0) {\n                resultValues[i] = v;\n            }\n            else {\n                resultValues[i] = alpha * v;\n            }\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.prelu = function (x, alpha) {\n        var resultValues = new Float32Array(x.size);\n        var values = x.dataSync();\n        var alphas = alpha.dataSync();\n        for (var i = 0; i < values.length; i++) {\n            var v = values[i];\n            if (v >= 0) {\n                resultValues[i] = v;\n            }\n            else {\n                resultValues[i] = alphas[i] * v;\n            }\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.preluDer = function (x, alpha) {\n        var resultValues = new Float32Array(x.size);\n        var values = x.dataSync();\n        var alphas = alpha.dataSync();\n        for (var i = 0; i < values.length; i++) {\n            var v = values[i];\n            if (v > 0) {\n                resultValues[i] = 1;\n            }\n            else if (v < 0) {\n                resultValues[i] = alphas[i];\n            }\n            else {\n                resultValues[i] = v;\n            }\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.clip = function (x, min, max) {\n        var resultValues = new Float32Array(x.size);\n        var values = x.dataSync();\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = Math.min(max, Math.max(min, values[i]));\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.abs = function (x) {\n        var resultValues = new Float32Array(x.size);\n        var values = x.dataSync();\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = Math.abs(values[i]);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.int = function (x) {\n        var resultValues = new Int32Array(x.size);\n        var values = x.dataSync();\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = values[i];\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues }, 'int32');\n    };\n    MathBackendCPU.prototype.sigmoid = function (x) {\n        var resultValues = new Float32Array(x.size);\n        var values = x.dataSync();\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = 1 / (1 + Math.exp(-values[i]));\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.sin = function (x) {\n        var resultValues = new Float32Array(x.size);\n        var values = x.dataSync();\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = Math.sin(values[i]);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.cos = function (x) {\n        var resultValues = new Float32Array(x.size);\n        var values = x.dataSync();\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = Math.cos(values[i]);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.tan = function (x) {\n        var resultValues = new Float32Array(x.size);\n        var values = x.dataSync();\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = Math.tan(values[i]);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.asin = function (x) {\n        var resultValues = new Float32Array(x.size);\n        var values = x.dataSync();\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = Math.asin(values[i]);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.acos = function (x) {\n        var resultValues = new Float32Array(x.size);\n        var values = x.dataSync();\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = Math.acos(values[i]);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.atan = function (x) {\n        var resultValues = new Float32Array(x.size);\n        var values = x.dataSync();\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = Math.atan(values[i]);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.sinh = function (x) {\n        var resultValues = new Float32Array(x.size);\n        var values = x.dataSync();\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = Math.sinh(values[i]);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.cosh = function (x) {\n        var resultValues = new Float32Array(x.size);\n        var values = x.dataSync();\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = Math.cosh(values[i]);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.tanh = function (x) {\n        var resultValues = new Float32Array(x.size);\n        var values = x.dataSync();\n        for (var i = 0; i < values.length; ++i) {\n            resultValues[i] = util.tanh(values[i]);\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.step = function (x, alpha) {\n        if (alpha === void 0) { alpha = 0; }\n        var resultValues = new Float32Array(x.size);\n        var values = x.dataSync();\n        for (var i = 0; i < values.length; ++i) {\n            var value = values[i];\n            if (util.isValNaN(value, x.dtype)) {\n                resultValues[i] = util.getNaN(x.dtype);\n            }\n            else {\n                resultValues[i] = value > 0 ? 1 : alpha;\n            }\n        }\n        return tensor_1.Tensor.make(x.shape, { values: resultValues });\n    };\n    MathBackendCPU.prototype.conv2d = function (x, filter, convInfo) {\n        var filterHeight = convInfo.filterHeight;\n        var filterWidth = convInfo.filterWidth;\n        var dilationHeight = convInfo.dilationHeight;\n        var dilationWidth = convInfo.dilationWidth;\n        var padLeft = convInfo.padInfo.left;\n        var padTop = convInfo.padInfo.top;\n        var y = ops.buffer(convInfo.outShape, x.dtype);\n        for (var b = 0; b < convInfo.batchSize; ++b) {\n            for (var d2 = 0; d2 < convInfo.outChannels; ++d2) {\n                for (var yR = 0; yR < convInfo.outHeight; ++yR) {\n                    var xRCorner = yR * convInfo.strideHeight - padLeft;\n                    for (var yC = 0; yC < convInfo.outWidth; ++yC) {\n                        var xCCorner = yC * convInfo.strideWidth - padTop;\n                        var dotProd = 0;\n                        for (var wR = 0; wR < filterHeight; wR++) {\n                            var xR = xRCorner + wR * dilationHeight;\n                            if (xR < 0 || xR >= convInfo.inHeight) {\n                                continue;\n                            }\n                            for (var wC = 0; wC < filterWidth; wC++) {\n                                var xC = xCCorner + wC * dilationWidth;\n                                if (xC < 0 || xC >= convInfo.inWidth) {\n                                    continue;\n                                }\n                                for (var d1 = 0; d1 < convInfo.inChannels; ++d1) {\n                                    var pixel = x.get(b, xR, xC, d1);\n                                    var weight = filter.get(wR, wC, d1, d2);\n                                    dotProd += pixel * weight;\n                                }\n                            }\n                        }\n                        y.set(dotProd, b, yR, yC, d2);\n                    }\n                }\n            }\n        }\n        return y.toTensor();\n    };\n    MathBackendCPU.prototype.conv2dDerInput = function (dy, filter, convInfo) {\n        var filterHeight = convInfo.filterHeight;\n        var filterWidth = convInfo.filterWidth;\n        var topPad = filterHeight - 1 - convInfo.padInfo.top;\n        var leftPad = filterWidth - 1 - convInfo.padInfo.left;\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var dx = ops.buffer(convInfo.inShape, 'float32');\n        for (var b = 0; b < convInfo.batchSize; ++b) {\n            for (var d1 = 0; d1 < convInfo.inChannels; ++d1) {\n                for (var xR = 0; xR < convInfo.inHeight; ++xR) {\n                    var xRCorner = xR - leftPad;\n                    var xRMin = Math.max(0, Math.ceil(xRCorner / strideHeight));\n                    var yRMax = Math.min(convInfo.outHeight, (filterHeight + xRCorner) / strideHeight);\n                    for (var xC = 0; xC < convInfo.inWidth; ++xC) {\n                        var xCCorner = xC - topPad;\n                        var xCMin = Math.max(0, Math.ceil(xCCorner / strideWidth));\n                        var yCMax = Math.min(convInfo.outWidth, (filterWidth + xCCorner) / strideWidth);\n                        var dotProd = 0;\n                        for (var yR = xRMin; yR < yRMax; ++yR) {\n                            var wR = yR * strideHeight - xRCorner;\n                            for (var yC = xCMin; yC < yCMax; ++yC) {\n                                var wC = yC * strideWidth - xCCorner;\n                                for (var d2 = 0; d2 < convInfo.outChannels; ++d2) {\n                                    var pixel = dy.get(b, yR, yC, d2);\n                                    var weight = filter.get(filterHeight - 1 - wR, filterWidth - 1 - wC, d1, d2);\n                                    dotProd += pixel * weight;\n                                }\n                            }\n                        }\n                        dx.set(dotProd, b, xR, xC, d1);\n                    }\n                }\n            }\n        }\n        return dx.toTensor();\n    };\n    MathBackendCPU.prototype.conv2dDerFilter = function (x, dy, convInfo) {\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var filterHeight = convInfo.filterHeight;\n        var filterWidth = convInfo.filterWidth;\n        var dW = ops.buffer(convInfo.filterShape, 'float32');\n        var leftPad = convInfo.padInfo.left;\n        var topPad = convInfo.padInfo.top;\n        for (var wR = 0; wR < filterHeight; ++wR) {\n            var yRMin = Math.max(0, Math.ceil((topPad - wR) / strideHeight));\n            var yRMax = Math.min(convInfo.outHeight, (convInfo.inHeight + topPad - wR) / strideHeight);\n            for (var wC = 0; wC < filterWidth; ++wC) {\n                var yCMin = Math.max(0, Math.ceil((leftPad - wC) / strideWidth));\n                var yCMax = Math.min(convInfo.outWidth, (convInfo.inWidth + leftPad - wC) / strideWidth);\n                for (var d1 = 0; d1 < convInfo.inChannels; ++d1) {\n                    for (var d2 = 0; d2 < convInfo.outChannels; ++d2) {\n                        var dotProd = 0;\n                        for (var b = 0; b < convInfo.batchSize; ++b) {\n                            for (var yR = yRMin; yR < yRMax; ++yR) {\n                                var xR = wR + yR * strideHeight - topPad;\n                                for (var yC = yCMin; yC < yCMax; ++yC) {\n                                    var xC = wC + yC * strideWidth - leftPad;\n                                    dotProd += x.get(b, xR, xC, d1) * dy.get(b, yR, yC, d2);\n                                }\n                            }\n                        }\n                        dW.set(dotProd, wR, wC, d1, d2);\n                    }\n                }\n            }\n        }\n        return dW.toTensor();\n    };\n    MathBackendCPU.prototype.depthwiseConv2D = function (x, filter, convInfo) {\n        var filterHeight = convInfo.filterHeight;\n        var filterWidth = convInfo.filterWidth;\n        var dilationHeight = convInfo.dilationHeight;\n        var dilationWidth = convInfo.dilationWidth;\n        var padLeft = convInfo.padInfo.left;\n        var padTop = convInfo.padInfo.top;\n        var chMul = convInfo.outChannels / convInfo.inChannels;\n        var y = ops.buffer(convInfo.outShape, x.dtype);\n        for (var b = 0; b < convInfo.batchSize; ++b) {\n            for (var d1 = 0; d1 < convInfo.inChannels; ++d1) {\n                for (var yR = 0; yR < convInfo.outHeight; ++yR) {\n                    var xRCorner = yR * convInfo.strideHeight - padLeft;\n                    for (var yC = 0; yC < convInfo.outWidth; ++yC) {\n                        var xCCorner = yC * convInfo.strideWidth - padTop;\n                        for (var q = 0; q < chMul; ++q) {\n                            var dotProd = 0;\n                            for (var wR = 0; wR < filterHeight; ++wR) {\n                                var xR = xRCorner + wR * dilationHeight;\n                                if (xR < 0 || xR >= convInfo.inHeight) {\n                                    continue;\n                                }\n                                for (var wC = 0; wC < filterWidth; ++wC) {\n                                    var xC = xCCorner + wC * dilationWidth;\n                                    if (xC < 0 || xC >= convInfo.inWidth) {\n                                        continue;\n                                    }\n                                    var pixel = x.get(b, xR, xC, d1);\n                                    var weight = filter.get(wR, wC, d1, q);\n                                    dotProd += pixel * weight;\n                                }\n                            }\n                            y.set(dotProd, b, yR, yC, d1 * chMul + q);\n                        }\n                    }\n                }\n            }\n        }\n        return y.toTensor();\n    };\n    MathBackendCPU.prototype.tile = function (x, reps) {\n        var newShape = new Array(x.rank);\n        for (var i = 0; i < newShape.length; i++) {\n            newShape[i] = x.shape[i] * reps[i];\n        }\n        var result = ops.buffer(newShape, x.dtype);\n        var xBuf = x.buffer();\n        for (var i = 0; i < result.values.length; ++i) {\n            var newLoc = result.indexToLoc(i);\n            var originalLoc = new Array(x.rank);\n            for (var i_1 = 0; i_1 < originalLoc.length; i_1++) {\n                originalLoc[i_1] = newLoc[i_1] % x.shape[i_1];\n            }\n            var originalIndex = xBuf.locToIndex(originalLoc);\n            result.values[i] = xBuf.values[originalIndex];\n        }\n        return result.toTensor();\n    };\n    MathBackendCPU.prototype.pad = function (x, paddings, constantValue) {\n        var outShape = paddings.map(function (p, i) { return p[0] + x.shape[i] + p[1]; });\n        var start = paddings.map(function (p) { return p[0]; });\n        var xBuffer = x.buffer();\n        var buffer = ops.buffer(outShape, x.dtype);\n        if (constantValue !== 0) {\n            buffer.values.fill(constantValue);\n        }\n        for (var i = 0; i < x.size; i++) {\n            var coords = xBuffer.indexToLoc(i);\n            var outCoords = coords.map(function (c, i) { return c + start[i]; });\n            buffer.set.apply(buffer, [x.get.apply(x, coords)].concat(outCoords));\n        }\n        return buffer.toTensor();\n    };\n    MathBackendCPU.prototype.transpose = function (x, perm) {\n        var newShape = new Array(x.rank);\n        for (var i = 0; i < newShape.length; i++) {\n            newShape[i] = x.shape[perm[i]];\n        }\n        var values = x.dataSync();\n        var result = ops_1.buffer(newShape, x.dtype);\n        var xBuf = x.buffer();\n        for (var i = 0; i < x.size; ++i) {\n            var loc = xBuf.indexToLoc(i);\n            var newLoc = new Array(loc.length);\n            for (var i_2 = 0; i_2 < newLoc.length; i_2++) {\n                newLoc[i_2] = loc[perm[i_2]];\n            }\n            var newIndex = result.locToIndex(newLoc);\n            result.values[newIndex] = values[i];\n        }\n        return result.toTensor();\n    };\n    MathBackendCPU.prototype.gather = function (x, indices, axis) {\n        var newShape = x.shape.slice();\n        var indicesValues = indices.dataSync();\n        newShape[axis] = indicesValues.length;\n        var result = ops_1.buffer(newShape, x.dtype);\n        var xBuf = x.buffer();\n        for (var i = 0; i < result.size; ++i) {\n            var newLoc = result.indexToLoc(i);\n            var originalLoc = newLoc.slice();\n            originalLoc[axis] = indicesValues[newLoc[axis]];\n            var originalIndex = xBuf.locToIndex(originalLoc);\n            result.values[i] = xBuf.values[originalIndex];\n        }\n        return result.toTensor();\n    };\n    MathBackendCPU.prototype.pool = function (x, convInfo, poolType) {\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var filterHeight = convInfo.filterHeight;\n        var filterWidth = convInfo.filterWidth;\n        var y = ops.buffer(convInfo.outShape, 'float32');\n        var padTop = convInfo.padInfo.top;\n        var padLeft = convInfo.padInfo.left;\n        for (var b = 0; b < convInfo.batchSize; ++b) {\n            for (var d = 0; d < convInfo.inChannels; ++d) {\n                for (var yR = 0; yR < convInfo.outHeight; ++yR) {\n                    var xRCorner = yR * strideHeight - padTop;\n                    var xRMin = Math.max(0, xRCorner);\n                    var xRMax = Math.min(convInfo.inHeight, filterHeight + xRCorner);\n                    for (var yC = 0; yC < convInfo.outWidth; ++yC) {\n                        var xCCorner = yC * strideWidth - padLeft;\n                        var xCMin = Math.max(0, xCCorner);\n                        var xCMax = Math.min(convInfo.inWidth, filterWidth + xCCorner);\n                        var minMaxValue = (poolType === 'max' ? Number.NEGATIVE_INFINITY :\n                            Number.POSITIVE_INFINITY);\n                        var avgValue = 0;\n                        for (var xR = xRMin; xR < xRMax; ++xR) {\n                            for (var xC = xCMin; xC < xCMax; ++xC) {\n                                var pixel = x.get(b, xR, xC, d);\n                                if (isNaN(pixel)) {\n                                    minMaxValue = NaN;\n                                    avgValue = NaN;\n                                    break;\n                                }\n                                if ((poolType === 'max' && pixel > minMaxValue) ||\n                                    (poolType === 'min' && pixel < minMaxValue)) {\n                                    minMaxValue = pixel;\n                                }\n                                else if (poolType === 'avg') {\n                                    avgValue += pixel / (filterHeight * filterWidth);\n                                }\n                            }\n                            if (isNaN(minMaxValue)) {\n                                break;\n                            }\n                        }\n                        y.set(poolType === 'avg' ? avgValue : minMaxValue, b, yR, yC, d);\n                    }\n                }\n            }\n        }\n        return y.toTensor();\n    };\n    MathBackendCPU.prototype.maxPool = function (x, convInfo) {\n        return this.pool(x, convInfo, 'max');\n    };\n    MathBackendCPU.prototype.maxPoolPositions = function (x, convInfo) {\n        var maxPositions = ops.buffer(convInfo.outShape, 'int32');\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var filterHeight = convInfo.filterHeight;\n        var filterWidth = convInfo.filterWidth;\n        var padTop = convInfo.padInfo.top;\n        var padLeft = convInfo.padInfo.left;\n        for (var b = 0; b < convInfo.batchSize; ++b) {\n            for (var d = 0; d < convInfo.inChannels; ++d) {\n                for (var yR = 0; yR < convInfo.outHeight; ++yR) {\n                    var xRCorner = yR * strideHeight - padTop;\n                    var xRMin = Math.max(0, xRCorner);\n                    var xRMax = Math.min(convInfo.inHeight, filterHeight + xRCorner);\n                    for (var yC = 0; yC < convInfo.outWidth; ++yC) {\n                        var xCCorner = yC * strideWidth - padLeft;\n                        var xCMin = Math.max(0, xCCorner);\n                        var xCMax = Math.min(convInfo.inWidth, filterWidth + xCCorner);\n                        var maxValue = Number.NEGATIVE_INFINITY;\n                        var maxPosition = -1;\n                        for (var xR = xRMin; xR < xRMax; ++xR) {\n                            var wR = xR - xRCorner;\n                            for (var xC = xCMin; xC < xCMax; ++xC) {\n                                var wC = xC - xCCorner;\n                                var pixel = x.get(b, xR, xC, d);\n                                if (pixel > maxValue) {\n                                    maxValue = pixel;\n                                    maxPosition = wR * filterWidth + wC;\n                                }\n                            }\n                        }\n                        maxPositions.set(maxPosition, b, yR, yC, d);\n                    }\n                }\n            }\n        }\n        return maxPositions.toTensor();\n    };\n    MathBackendCPU.prototype.maxPoolBackprop = function (dy, x, convInfo) {\n        var maxPositions = this.maxPoolPositions(x, convInfo);\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var filterHeight = convInfo.filterHeight;\n        var filterWidth = convInfo.filterWidth;\n        var padLeft = filterWidth - 1 - convInfo.padInfo.left;\n        var padTop = filterHeight - 1 - convInfo.padInfo.top;\n        var dx = ops.buffer(x.shape, 'float32');\n        for (var b = 0; b < convInfo.batchSize; ++b) {\n            for (var d = 0; d < convInfo.inChannels; ++d) {\n                for (var dxR = 0; dxR < convInfo.inHeight; ++dxR) {\n                    for (var dxC = 0; dxC < convInfo.inWidth; ++dxC) {\n                        var dyRCorner = dxR - padTop;\n                        var dyCCorner = dxC - padLeft;\n                        var dotProd = 0;\n                        for (var wR = 0; wR < filterHeight; ++wR) {\n                            var dyR = (dyRCorner + wR) / strideHeight;\n                            if (dyR < 0 || dyR >= convInfo.outHeight ||\n                                Math.floor(dyR) !== dyR) {\n                                continue;\n                            }\n                            for (var wC = 0; wC < filterWidth; ++wC) {\n                                var dyC = (dyCCorner + wC) / strideWidth;\n                                if (dyC < 0 || dyC >= convInfo.outWidth ||\n                                    Math.floor(dyC) !== dyC) {\n                                    continue;\n                                }\n                                var maxPos = filterHeight * filterWidth - 1 -\n                                    maxPositions.get(b, dyR, dyC, d);\n                                var curPos = wR * filterWidth + wC;\n                                var mask = maxPos === curPos ? 1 : 0;\n                                if (mask === 0) {\n                                    continue;\n                                }\n                                var pixel = dy.get(b, dyR, dyC, d);\n                                dotProd += pixel * mask;\n                            }\n                        }\n                        dx.set(dotProd, b, dxR, dxC, d);\n                    }\n                }\n            }\n        }\n        return dx.toTensor();\n    };\n    MathBackendCPU.prototype.avgPoolBackprop = function (dy, x, convInfo) {\n        var strideHeight = convInfo.strideHeight;\n        var strideWidth = convInfo.strideWidth;\n        var filterHeight = convInfo.filterHeight;\n        var filterWidth = convInfo.filterWidth;\n        var padLeft = filterWidth - 1 - convInfo.padInfo.left;\n        var padTop = filterHeight - 1 - convInfo.padInfo.top;\n        var dx = ops.buffer(x.shape, 'float32');\n        var avgMultiplier = 1 / (filterHeight * filterWidth);\n        for (var b = 0; b < convInfo.batchSize; ++b) {\n            for (var d = 0; d < convInfo.inChannels; ++d) {\n                for (var dxR = 0; dxR < convInfo.inHeight; ++dxR) {\n                    for (var dxC = 0; dxC < convInfo.inWidth; ++dxC) {\n                        var dyRCorner = dxR - padTop;\n                        var dyCCorner = dxC - padLeft;\n                        var dotProd = 0;\n                        for (var wR = 0; wR < filterHeight; ++wR) {\n                            var dyR = (dyRCorner + wR) / strideHeight;\n                            if (dyR < 0 || dyR >= convInfo.outHeight ||\n                                Math.floor(dyR) !== dyR) {\n                                continue;\n                            }\n                            for (var wC = 0; wC < filterWidth; ++wC) {\n                                var dyC = (dyCCorner + wC) / strideWidth;\n                                if (dyC < 0 || dyC >= convInfo.outWidth ||\n                                    Math.floor(dyC) !== dyC) {\n                                    continue;\n                                }\n                                var pixel = dy.get(b, dyR, dyC, d);\n                                dotProd += pixel;\n                            }\n                        }\n                        dx.set(dotProd * avgMultiplier, b, dxR, dxC, d);\n                    }\n                }\n            }\n        }\n        return dx.toTensor();\n    };\n    MathBackendCPU.prototype.cast = function (x, dtype) {\n        return backend_util.castTensor(x, dtype, this);\n    };\n    MathBackendCPU.prototype.reshape = function (x, shape) {\n        return backend_util.reshapeTensor(x, shape);\n    };\n    MathBackendCPU.prototype.minPool = function (x, convInfo) {\n        return this.pool(x, convInfo, 'min');\n    };\n    MathBackendCPU.prototype.avgPool = function (x, convInfo) {\n        return this.pool(x, convInfo, 'avg').toFloat();\n    };\n    MathBackendCPU.prototype.resizeBilinear = function (x, newHeight, newWidth, alignCorners) {\n        var _a = x.shape, batch = _a[0], oldHeight = _a[1], oldWidth = _a[2], numChannels = _a[3];\n        var output = ops.buffer([batch, newHeight, newWidth, numChannels], x.dtype);\n        var effectiveInputSize = alignCorners ? [oldHeight - 1, oldWidth - 1] : [oldHeight, oldWidth];\n        var effectiveOutputSize = alignCorners ? [newHeight - 1, newWidth - 1] : [newHeight, newWidth];\n        for (var b = 0; b < batch; b++) {\n            for (var r = 0; r < newHeight; r++) {\n                for (var c = 0; c < newWidth; c++) {\n                    for (var d = 0; d < numChannels; d++) {\n                        var sourceFracRow = (effectiveInputSize[0]) * r / (effectiveOutputSize[0]);\n                        var sourceFracCol = (effectiveInputSize[1]) * c / (effectiveOutputSize[1]);\n                        var sourceRowFloor = Math.floor(sourceFracRow);\n                        var sourceRowCeil = Math.min(oldHeight - 1, Math.ceil(sourceFracRow));\n                        var sourceColFloor = Math.floor(sourceFracCol);\n                        var sourceColCeil = Math.min(oldWidth - 1, Math.ceil(sourceFracCol));\n                        var topLeft = x.get(b, sourceRowFloor, sourceColFloor, d);\n                        var bottomLeft = x.get(b, sourceRowCeil, sourceColFloor, d);\n                        var topRight = x.get(b, sourceRowFloor, sourceColCeil, d);\n                        var bottomRight = x.get(b, sourceRowCeil, sourceColCeil, d);\n                        var rowFrac = sourceFracRow - sourceRowFloor;\n                        var colFrac = sourceFracCol - sourceColFloor;\n                        var top_1 = topLeft + (topRight - topLeft) * colFrac;\n                        var bottom = bottomLeft + (bottomRight - bottomLeft) * colFrac;\n                        var newValue = top_1 + (bottom - top_1) * rowFrac;\n                        output.set(newValue, b, r, c, d);\n                    }\n                }\n            }\n        }\n        return output.toTensor();\n    };\n    MathBackendCPU.prototype.batchNormalization4D = function (x, mean, variance, varianceEpsilon, scale, offset) {\n        var xValues = x.dataSync();\n        var meanValues = mean.dataSync();\n        var varianceValues = variance.dataSync();\n        var scaleValues = scale ? scale.dataSync() : new Float32Array([1]);\n        var offsetValues = offset ? offset.dataSync() : new Float32Array([0]);\n        var outValues = new Float32Array(xValues.length);\n        for (var i = 0; i < xValues.length; i++) {\n            outValues[i] = offsetValues[i % offsetValues.length] +\n                (xValues[i] - meanValues[i % meanValues.length]) *\n                    scaleValues[i % scaleValues.length] /\n                    Math.sqrt(varianceValues[i % varianceValues.length] + varianceEpsilon);\n        }\n        return ops_1.tensor4d(outValues, x.shape);\n    };\n    MathBackendCPU.prototype.localResponseNormalization4D = function (x, radius, bias, alpha, beta, normRegion) {\n        var output = ops.buffer(x.shape, 'float32');\n        var rad = radius;\n        var maxW = output.shape[1] - 1;\n        var maxH = output.shape[2] - 1;\n        var maxD = output.shape[3] - 1;\n        var sumAcrossChannels = function (b, r, c, d) {\n            var sum = 0.0;\n            for (var j = Math.max(0, d - rad); j <= Math.min(d + rad, maxD); j++) {\n                var z = x.get(b, r, c, j);\n                sum += z * z;\n            }\n            return sum;\n        };\n        var sumWithinChannel = function (b, r, c, d) {\n            var sum = 0.0;\n            for (var u = Math.max(0, r - rad); u <= Math.min(r + rad, maxW); u++) {\n                for (var v = Math.max(0, c - rad); v <= Math.min(c + rad, maxH); v++) {\n                    sum += Math.pow(x.get(b, u, v, d), 2);\n                }\n            }\n            return sum;\n        };\n        for (var b = 0; b < output.shape[0]; b++) {\n            for (var r = 0; r <= output.shape[1]; r++) {\n                for (var c = 0; c < output.shape[2]; c++) {\n                    for (var d = 0; d < output.shape[3]; d++) {\n                        var sum = normRegion === 'withinChannel' ?\n                            sumWithinChannel(b, r, c, d) :\n                            sumAcrossChannels(b, r, c, d);\n                        var val = x.get(b, r, c, d) * Math.pow(bias + alpha * sum, -beta);\n                        output.set(val, b, r, c, d);\n                    }\n                }\n            }\n        }\n        return output.toTensor();\n    };\n    MathBackendCPU.prototype.multinomial = function (probabilities, numSamples, seed) {\n        var batchSize = probabilities.shape[0];\n        var numEvents = probabilities.shape[1];\n        var res = ops.zeros([batchSize, numSamples], 'int32');\n        var resVals = res.dataSync();\n        var probVals = probabilities.dataSync();\n        for (var b = 0; b < batchSize; ++b) {\n            var offset = b * numEvents;\n            var cdf = new Float32Array(numEvents - 1);\n            cdf[0] = probVals[offset];\n            for (var event_1 = 1; event_1 < cdf.length; ++event_1) {\n                cdf[event_1] = cdf[event_1 - 1] + probVals[offset + event_1];\n            }\n            var random = seedrandom.alea(seed.toString());\n            var outOffset = b * numSamples;\n            for (var sampleId = 0; sampleId < numSamples; ++sampleId) {\n                var r = random();\n                resVals[outOffset + sampleId] = cdf.length;\n                for (var event_2 = 0; event_2 < cdf.length; event_2++) {\n                    if (r < cdf[event_2]) {\n                        resVals[outOffset + sampleId] = event_2;\n                        break;\n                    }\n                }\n            }\n        }\n        return res;\n    };\n    MathBackendCPU.prototype.oneHot = function (indices, depth, onValue, offValue) {\n        var res = new Float32Array(indices.size * depth);\n        res.fill(offValue);\n        for (var event_3 = 0; event_3 < indices.size; ++event_3) {\n            res[event_3 * depth + indices.get(event_3)] = onValue;\n        }\n        return ops.tensor2d(res, [indices.size, depth]);\n    };\n    MathBackendCPU.prototype.broadcastedBinaryOp = function (a, b, dtype, op) {\n        var newShape = broadcast_util.assertAndGetBroadcastShape(a.shape, b.shape);\n        var result = ops.buffer(newShape, dtype);\n        var aValues = a.dataSync();\n        var bValues = b.dataSync();\n        var aBroadcastDims = broadcast_util.getBroadcastDims(a.shape, newShape);\n        var bBroadcastDims = broadcast_util.getBroadcastDims(b.shape, newShape);\n        var aBuf = a.buffer();\n        var bBuf = b.buffer();\n        var _loop_2 = function (i) {\n            var loc = result.indexToLoc(i);\n            var aLoc = loc.slice(-a.rank);\n            aBroadcastDims.forEach(function (d) { return aLoc[d] = 0; });\n            var aIndex = aBuf.locToIndex(aLoc);\n            var bLoc = loc.slice(-b.rank);\n            bBroadcastDims.forEach(function (d) { return bLoc[d] = 0; });\n            var bIndex = bBuf.locToIndex(bLoc);\n            result.values[i] = op(aValues[aIndex], bValues[bIndex]);\n        };\n        for (var i = 0; i < result.values.length; ++i) {\n            _loop_2(i);\n        }\n        return result.toTensor();\n    };\n    MathBackendCPU.prototype.dispose = function () { };\n    return MathBackendCPU;\n}());\nexports.MathBackendCPU = MathBackendCPU;\nenvironment_1.ENV.registerBackend('cpu', function () { return new MathBackendCPU(); });\n"},"hash":"2770f2dd2e22edd1c4224d1ae7fceb91","cacheData":{"env":{}}}