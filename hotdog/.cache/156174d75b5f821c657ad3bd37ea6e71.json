{"dependencies":[{"name":"/Users/sanghan/Desktop/tfjs-examples/mobilenet/package.json","includedInParent":true,"mtime":1522644996454},{"name":"/Users/sanghan/Desktop/tfjs-examples/mobilenet/node_modules/@tensorflow/tfjs-layers/package.json","includedInParent":true,"mtime":1522260134000},{"name":"@tensorflow/tfjs-core","loc":{"line":19,"column":26}},{"name":"underscore","loc":{"line":20,"column":16}},{"name":"../backend/tfjs_backend","loc":{"line":21,"column":16}},{"name":"../errors","loc":{"line":22,"column":23}},{"name":"../layers/serialization","loc":{"line":23,"column":30}},{"name":"../types","loc":{"line":24,"column":22}},{"name":"../utils/generic_utils","loc":{"line":25,"column":28}},{"name":"../utils/serialization_utils","loc":{"line":26,"column":36}}],"generated":{"js":"\"use strict\";\nvar __extends = (this && this.__extends) || (function () {\n    var extendStatics = Object.setPrototypeOf ||\n        ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n        function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\n    return function (d, b) {\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    };\n})();\nvar __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {\n    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;\n    if (typeof Reflect === \"object\" && typeof Reflect.decorate === \"function\") r = Reflect.decorate(decorators, target, key, desc);\n    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;\n    return c > 3 && r && Object.defineProperty(target, key, r), r;\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar tfjs_core_1 = require(\"@tensorflow/tfjs-core\");\nvar _ = require(\"underscore\");\nvar K = require(\"../backend/tfjs_backend\");\nvar errors_1 = require(\"../errors\");\nvar serialization_1 = require(\"../layers/serialization\");\nvar types_1 = require(\"../types\");\nvar generic_utils = require(\"../utils/generic_utils\");\nvar serialization_utils_1 = require(\"../utils/serialization_utils\");\nvar InputSpec = (function () {\n    function InputSpec(config) {\n        this.dtype = config.dtype;\n        this.shape = config.shape;\n        if (config.shape != null) {\n            this.ndim = config.shape.length;\n        }\n        else {\n            this.ndim = config.ndim;\n        }\n        this.maxNDim = config.maxNDim;\n        this.minNDim = config.minNDim;\n        this.axes = config.axes || {};\n    }\n    return InputSpec;\n}());\nexports.InputSpec = InputSpec;\nvar _nextNodeID = 0;\nvar Node = (function () {\n    function Node(config, callArgs) {\n        this.callArgs = callArgs;\n        this.id = _nextNodeID++;\n        this.outboundLayer = config.outboundLayer;\n        this.inboundLayers = config.inboundLayers;\n        this.nodeIndices = config.nodeIndices;\n        this.tensorIndices = config.tensorIndices;\n        this.inputTensors = config.inputTensors;\n        this.outputTensors = config.outputTensors;\n        this.inputMasks = config.inputMasks;\n        this.outputMasks = config.outputMasks;\n        this.inputShapes = config.inputShapes;\n        this.outputShapes = config.outputShapes;\n        for (var _i = 0, _a = config.inboundLayers; _i < _a.length; _i++) {\n            var layer = _a[_i];\n            if (layer != null) {\n                layer.outboundNodes.push(this);\n            }\n        }\n        config.outboundLayer.inboundNodes.push(this);\n    }\n    Node.prototype.getConfig = function () {\n        var inboundNames = [];\n        for (var _i = 0, _a = this.inboundLayers; _i < _a.length; _i++) {\n            var layer = _a[_i];\n            if (layer != null) {\n                inboundNames.push(layer.name);\n            }\n            else {\n                inboundNames.push(null);\n            }\n        }\n        return {\n            outboundLayer: this.outboundLayer ? this.outboundLayer.name : null,\n            inboundLayers: inboundNames,\n            nodeIndices: this.nodeIndices,\n            tensorIndices: this.tensorIndices\n        };\n    };\n    return Node;\n}());\nexports.Node = Node;\nvar _nextLayerID = 0;\nvar Layer = (function () {\n    function Layer(config) {\n        this._callHook = null;\n        this._stateful = false;\n        this.id = _nextLayerID++;\n        this.activityRegularizer = null;\n        this.inputSpec = null;\n        this.supportsMasking = false;\n        this._trainableWeights = [];\n        this._nonTrainableWeights = [];\n        this._losses = [];\n        this._updates = [];\n        this._built = false;\n        this.inboundNodes = [];\n        this.outboundNodes = [];\n        var name = config.name;\n        if (!name) {\n            var prefix = this.constructor.name;\n            name = generic_utils.toSnakeCase(prefix) + '_' + K.getUid(prefix);\n        }\n        this.name = name;\n        this.trainable = generic_utils.pyGetAttr(config, 'trainable', true);\n        this.updatable = generic_utils.pyGetAttr(config, 'updatable', true);\n        if (config.inputShape != null || config.batchInputShape != null) {\n            var batchInputShape = void 0;\n            if (config.batchInputShape != null) {\n                batchInputShape = config.batchInputShape;\n            }\n            else if (config.inputShape != null) {\n                var batchSize = null;\n                if (config.batchSize != null) {\n                    batchSize = config.batchSize;\n                }\n                batchInputShape = [batchSize].concat(config.inputShape);\n            }\n            this.batchInputShape = batchInputShape;\n            var dtype = config.dtype;\n            if (dtype == null) {\n                dtype = config.inputDType;\n            }\n            if (dtype == null) {\n                dtype = K.floatx();\n            }\n            this.dtype = dtype;\n        }\n        if (config.weights != null) {\n            this.initialWeights = config.weights;\n        }\n        else {\n            this.initialWeights = null;\n        }\n    }\n    Layer.nodeKey = function (layer, nodeIndex) {\n        return layer.name + '_ib-' + nodeIndex.toString();\n    };\n    Layer.prototype.getNodeAtIndex = function (nodeIndex, attrName) {\n        if (this.inboundNodes.length === 0) {\n            throw new errors_1.RuntimeError('The layer has never been called ' +\n                (\"and thus has no defined \" + attrName + \".\"));\n        }\n        if (this.inboundNodes.length <= nodeIndex) {\n            throw new errors_1.ValueError(\"Asked to get \" + attrName + \" at node \" + nodeIndex + \", \" +\n                (\"but the layer has only \" + this.inboundNodes.length + \" inbound nodes.\"));\n        }\n        return this.inboundNodes[nodeIndex];\n    };\n    Layer.prototype.getInputAt = function (nodeIndex) {\n        return generic_utils.singletonOrArray(this.getNodeAtIndex(nodeIndex, 'input').inputTensors);\n    };\n    Layer.prototype.getOutputAt = function (nodeIndex) {\n        return generic_utils.singletonOrArray(this.getNodeAtIndex(nodeIndex, 'output').outputTensors);\n    };\n    Object.defineProperty(Layer.prototype, \"input\", {\n        get: function () {\n            if (this.inboundNodes.length > 1) {\n                throw new errors_1.AttributeError(\"Layer \" + this.name +\n                    ' has multiple inbound nodes, ' +\n                    'hence the notion of \"layer input\" ' +\n                    'is ill-defined. ' +\n                    'Use `getInputAt(nodeIndex)` instead.');\n            }\n            else if (this.inboundNodes.length === 0) {\n                throw new errors_1.AttributeError(\"Layer \" + this.name +\n                    ' is not connected, no input to return.');\n            }\n            return generic_utils.singletonOrArray(this.getNodeAtIndex(0, 'input').inputTensors);\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(Layer.prototype, \"output\", {\n        get: function () {\n            if (this.inboundNodes.length === 0) {\n                throw new errors_1.AttributeError(\"Layer \" + this.name +\n                    ' has no inbound nodes.');\n            }\n            if (this.inboundNodes.length > 1) {\n                throw new errors_1.AttributeError(\"Layer \" + this.name +\n                    ' has multiple inbound nodes, ' +\n                    'hence the notion of \"layer output\" ' +\n                    'is ill-defined. ' +\n                    'Use `getOutputAt(nodeIndex)` instead.');\n            }\n            return generic_utils.singletonOrArray(this.getNodeAtIndex(0, 'output').outputTensors);\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(Layer.prototype, \"losses\", {\n        get: function () {\n            return this._losses;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Layer.prototype.calculateLosses = function () {\n        return this.losses.map(function (lossFn) { return lossFn(); });\n    };\n    Object.defineProperty(Layer.prototype, \"updates\", {\n        get: function () {\n            return this._updates;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(Layer.prototype, \"built\", {\n        get: function () {\n            return this._built;\n        },\n        set: function (built) {\n            this._built = built;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(Layer.prototype, \"trainableWeights\", {\n        get: function () {\n            if (this.trainable) {\n                return this._trainableWeights;\n            }\n            else {\n                return [];\n            }\n        },\n        set: function (weights) {\n            this._trainableWeights = weights;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(Layer.prototype, \"nonTrainableWeights\", {\n        get: function () {\n            if (!this.trainable) {\n                return this._trainableWeights.concat(this._nonTrainableWeights);\n            }\n            else {\n                return this._nonTrainableWeights;\n            }\n        },\n        set: function (weights) {\n            this._nonTrainableWeights = weights;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(Layer.prototype, \"weights\", {\n        get: function () {\n            return this.trainableWeights.concat(this.nonTrainableWeights);\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(Layer.prototype, \"stateful\", {\n        get: function () {\n            return this._stateful;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Layer.prototype.assertInputCompatibility = function (inputs) {\n        inputs = generic_utils.toList(inputs);\n        if (this.inputSpec == null || this.inputSpec.length === 0) {\n            return;\n        }\n        var inputSpec = generic_utils.toList(this.inputSpec);\n        if (inputs.length !== inputSpec.length) {\n            throw new errors_1.ValueError(\"Layer \" + this.name + \" expects \" + inputSpec.length + \" inputs, \" +\n                (\"but it received \" + inputs.length + \" input tensors. \") +\n                (\"Input received: \" + inputs));\n        }\n        for (var inputIndex = 0; inputIndex < inputs.length; inputIndex++) {\n            var x = inputs[inputIndex];\n            var spec = inputSpec[inputIndex];\n            if (spec == null) {\n                continue;\n            }\n            var ndim = K.ndim(x);\n            if (spec.ndim != null) {\n                if (ndim !== spec.ndim) {\n                    throw new errors_1.ValueError(\"Input \" + inputIndex + \" is incompatible with layer \" + this.name + \": \" +\n                        (\"expected ndim=\" + spec.ndim + \", found ndim=\" + ndim));\n                }\n            }\n            if (spec.maxNDim != null) {\n                if (ndim > spec.maxNDim) {\n                    throw new errors_1.ValueError(\"Input \" + inputIndex + \" is incompatible with layer \" + this.name +\n                        (\": expected max_ndim=\" + spec.maxNDim + \", found ndim=\" + ndim));\n                }\n            }\n            if (spec.minNDim != null) {\n                if (ndim < spec.minNDim) {\n                    throw new errors_1.ValueError(\"Input \" + inputIndex + \" is incompatible with layer \" + this.name +\n                        (\": expected min_ndim=\" + spec.minNDim + \", found ndim=\" + ndim + \".\"));\n                }\n            }\n            if (spec.dtype != null) {\n                if (K.dtype(x) !== spec.dtype) {\n                    var xDType = K.dtype(x);\n                    throw new errors_1.ValueError(\"Input \" + inputIndex + \" is incompatible with layer \" + this.name + \" \" +\n                        (\": expected dtype=\" + spec.dtype + \", found dtype=\" + xDType + \".\"));\n                }\n            }\n            if (spec.axes) {\n                var xShape = K.intShape(x);\n                for (var _i = 0, _a = _.pairs(spec.axes); _i < _a.length; _i++) {\n                    var pair = _a[_i];\n                    var axis = pair[0];\n                    var value = pair[1];\n                    axis = Number(axis);\n                    var xShapeAtAxis = axis >= 0 ? xShape[axis] : xShape[xShape.length + axis];\n                    if (value != null && !_.contains([value, null], xShapeAtAxis)) {\n                        throw new errors_1.ValueError(\"Input \" + inputIndex + \" is incompatible with layer \" +\n                            (this.name + \": expected axis \" + axis + \" of input shape to \") +\n                            (\"have value \" + value + \" but got shape \" + xShape + \".\"));\n                    }\n                }\n            }\n            if (spec.shape != null) {\n                var xShape = K.intShape(x);\n                for (var _b = 0, _c = _.zip(spec.shape, xShape); _b < _c.length; _b++) {\n                    var _d = _c[_b], specDim = _d[0], dim = _d[1];\n                    if (specDim != null && dim != null) {\n                        if (specDim !== dim) {\n                            throw new errors_1.ValueError(\"Input \" + inputIndex + \" is incompatible with layer \" +\n                                (this.name + \": expected shape=\" + spec.shape + \", \") +\n                                'found shape=${xShape}.');\n                        }\n                    }\n                }\n            }\n        }\n    };\n    Layer.prototype.call = function (inputs, kwargs) {\n        return inputs;\n    };\n    Layer.prototype.invokeCallHook = function (inputs, kwargs) {\n        if (this._callHook != null) {\n            this._callHook(inputs, kwargs);\n        }\n    };\n    Layer.prototype.setCallHook = function (callHook) {\n        this._callHook = callHook;\n    };\n    Layer.prototype.clearCallHook = function () {\n        this._callHook = null;\n    };\n    Layer.prototype.apply = function (inputs, kwargs) {\n        var _this = this;\n        kwargs = kwargs || {};\n        var inputsList = generic_utils.toList(inputs);\n        var allAreSymbolic = _.every(inputsList, function (x) { return x instanceof types_1.SymbolicTensor; });\n        var noneAreSymbolic = _.every(inputsList, function (x) { return !(x instanceof types_1.SymbolicTensor); });\n        if (allAreSymbolic === noneAreSymbolic) {\n            throw new errors_1.ValueError('Arguments to apply() must be all ' +\n                'SymbolicTensors or all Tensors');\n        }\n        return K.nameScope(this.name, function () {\n            if (!_this.built) {\n                _this.assertInputCompatibility(inputs);\n                var inputShapes = [];\n                for (var _i = 0, _a = generic_utils.toList(inputs); _i < _a.length; _i++) {\n                    var xElem = _a[_i];\n                    inputShapes.push(K.intShape(xElem));\n                }\n                _this.build(generic_utils.singletonOrArray(inputShapes));\n                _this.built = true;\n                if (_this.initialWeights) {\n                    _this.setWeights(_this.initialWeights);\n                }\n            }\n            _this.assertInputCompatibility(inputs);\n            if (noneAreSymbolic) {\n                var output = _this.call(inputs, kwargs);\n                var outputList = generic_utils.toList(output);\n                var outputListCopy = [];\n                for (var _b = 0, outputList_1 = outputList; _b < outputList_1.length; _b++) {\n                    var x = outputList_1[_b];\n                    if (_.contains(inputsList, x)) {\n                        x = K.identity(x);\n                    }\n                    outputListCopy.push(x);\n                }\n                output = generic_utils.singletonOrArray(outputListCopy);\n                if (_this.activityRegularizer != null) {\n                    throw new errors_1.NotImplementedError('Layer invocation in the presence of activity ' +\n                        'regularizer(s) is not supported yet.');\n                }\n                return output;\n            }\n            else {\n                var inputShape = collectInputShape(inputs);\n                var outputShape = _this.computeOutputShape(inputShape);\n                var output = void 0;\n                var outputDType_1 = guessOutputDType(inputs);\n                if (outputShape != null && outputShape.length > 0 &&\n                    Array.isArray(outputShape[0])) {\n                    output = outputShape\n                        .map(function (shape, index) { return new types_1.SymbolicTensor(outputDType_1, shape, _this, generic_utils.toList(inputs), kwargs, _this.name, index); });\n                }\n                else {\n                    output = new types_1.SymbolicTensor(outputDType_1, outputShape, _this, generic_utils.toList(inputs), kwargs, _this.name);\n                }\n                _this.addInboundNode(inputs, output, null, null, inputShape, outputShape, kwargs);\n                if (_this.activityRegularizer != null) {\n                    throw new errors_1.NotImplementedError('Layer invocation in the presence of activity ' +\n                        'regularizer(s) is not supported yet.');\n                }\n                return output;\n            }\n        });\n    };\n    Layer.prototype.build = function (inputShape) {\n        this.built = true;\n    };\n    Layer.prototype.getWeights = function () {\n        return K.batchGetValue(this.weights);\n    };\n    Layer.prototype.setWeights = function (weights) {\n        var params = this.weights;\n        if (params.length !== weights.length) {\n            throw new errors_1.ValueError(\"You called setWeights(weights) on layer \\\"\" + this.name + \"\\\" \" +\n                (\"with a weight list of length \" + weights.length + \", \") +\n                (\"but the layer was expecting \" + params.length + \" weights. \") +\n                (\"Provided weights: \" + weights + \"...\"));\n        }\n        if (params.length === 0) {\n            return;\n        }\n        var weightValueTuples = [];\n        var paramValues = K.batchGetValue(params);\n        for (var _i = 0, _a = _.zip(paramValues, params, weights); _i < _a.length; _i++) {\n            var _b = _a[_i], pv = _b[0], p = _b[1], w = _b[2];\n            if (!_.isEqual(pv.shape, w.shape)) {\n                throw new errors_1.ValueError(\"Layer weight shape \" + pv.shape + \" \" +\n                    (\"not compatible with provided weight shape \" + w.shape));\n            }\n            weightValueTuples.push([p, w]);\n        }\n        K.batchSetValue(weightValueTuples);\n    };\n    Layer.prototype.addWeight = function (name, shape, dtype, initializer, regularizer, trainable, constraint) {\n        if (dtype == null) {\n            dtype = K.floatx();\n        }\n        var weight = new types_1.LayerVariable(initializer.apply(shape, dtype), dtype, name, trainable, constraint);\n        if (regularizer != null) {\n            this.addLoss(function () { return regularizer.apply(weight.read()); });\n        }\n        if (trainable == null) {\n            trainable = true;\n        }\n        if (trainable) {\n            this._trainableWeights.push(weight);\n        }\n        else {\n            this._nonTrainableWeights.push(weight);\n        }\n        return weight;\n    };\n    Layer.prototype.addLoss = function (losses) {\n        if (losses == null || Array.isArray(losses) && losses.length === 0) {\n            return;\n        }\n        losses = generic_utils.toList(losses);\n        if (this._losses !== undefined && this._losses !== null) {\n            (_a = this.losses).push.apply(_a, losses);\n        }\n        var _a;\n    };\n    Layer.prototype.computeOutputShape = function (inputShape) {\n        return inputShape;\n    };\n    Layer.prototype.computeMask = function (inputs, mask) {\n        if (!this.supportsMasking) {\n            if (mask != null) {\n                if (Array.isArray(mask)) {\n                    if (_.any(mask)) {\n                        throw new TypeError(\"Layer \" + this.name + \" does not support masking,\" +\n                            'but was passed an inputMask.');\n                    }\n                }\n                else {\n                    throw new TypeError(\"Layer \" + this.name + \" does not support masking,\" +\n                        'but was passed an inputMask.');\n                }\n            }\n            return null;\n        }\n        return mask;\n    };\n    Layer.prototype.addInboundNode = function (inputTensors, outputTensors, inputMasks, outputMasks, inputShapes, outputShapes, kwargs) {\n        if (kwargs === void 0) { kwargs = null; }\n        var inputTensorList = generic_utils.toList(inputTensors);\n        outputTensors = generic_utils.toList(outputTensors);\n        inputMasks = generic_utils.toList(inputMasks);\n        outputMasks = generic_utils.toList(outputMasks);\n        inputShapes = generic_utils.normalizeShapeList(inputShapes);\n        outputShapes = generic_utils.normalizeShapeList(outputShapes);\n        var inboundLayers = [];\n        var nodeIndices = [];\n        var tensorIndices = [];\n        for (var _i = 0, inputTensorList_1 = inputTensorList; _i < inputTensorList_1.length; _i++) {\n            var x = inputTensorList_1[_i];\n            inboundLayers.push(x.sourceLayer);\n            nodeIndices.push(x.nodeIndex);\n            tensorIndices.push(x.tensorIndex);\n        }\n        new Node({\n            outboundLayer: this,\n            inboundLayers: inboundLayers,\n            nodeIndices: nodeIndices,\n            tensorIndices: tensorIndices,\n            inputTensors: inputTensorList,\n            outputTensors: outputTensors,\n            inputMasks: inputMasks,\n            outputMasks: outputMasks,\n            inputShapes: inputShapes,\n            outputShapes: outputShapes\n        }, kwargs);\n        for (var i = 0; i < outputTensors.length; i++) {\n            outputTensors[i].sourceLayer = this;\n            outputTensors[i].nodeIndex = this.inboundNodes.length - 1;\n            outputTensors[i].tensorIndex = i;\n        }\n    };\n    Layer.prototype.getConfig = function () {\n        var config = { name: this.name, trainable: this.trainable };\n        if (this.batchInputShape != null) {\n            config['batchInputShape'] = this.batchInputShape;\n        }\n        if (this.dtype != null) {\n            config['dtype'] = this.dtype;\n        }\n        return config;\n    };\n    Layer.fromConfig = function (cls, config) {\n        return new cls(config);\n    };\n    __decorate([\n        tfjs_core_1.doc({ heading: 'Models', 'subheading': 'Classes' })\n    ], Layer.prototype, \"apply\", null);\n    Layer = __decorate([\n        tfjs_core_1.doc({ heading: 'Layers', subheading: 'Classes', namespace: 'layers' })\n    ], Layer);\n    return Layer;\n}());\nexports.Layer = Layer;\nfunction collectInputShape(inputTensors) {\n    inputTensors =\n        generic_utils.toList(inputTensors);\n    var shapes = [];\n    for (var _i = 0, inputTensors_1 = inputTensors; _i < inputTensors_1.length; _i++) {\n        var x = inputTensors_1[_i];\n        shapes.push(K.intShape(x));\n    }\n    return generic_utils.singletonOrArray(shapes);\n}\nfunction guessOutputDType(inputTensors) {\n    return types_1.DType.float32;\n}\nvar InputLayer = (function (_super) {\n    __extends(InputLayer, _super);\n    function InputLayer(config) {\n        var _this = _super.call(this, {\n            dtype: config.dtype,\n            name: config.name != null ? config.name : K.getUid('input').toString()\n        }) || this;\n        if (config.batchSize == null) {\n            config.batchSize = null;\n        }\n        if (config.sparse == null) {\n            config.sparse = false;\n        }\n        _this.trainable = false;\n        _this.built = true;\n        _this.sparse = config.sparse;\n        if (config.inputShape != null && config.batchInputShape != null) {\n            throw new errors_1.ValueError('Only provide the inputShape OR ' +\n                'batchInputShape argument to inputLayer, not both at the same time.');\n        }\n        var batchInputShape = config.batchInputShape;\n        if (batchInputShape == null) {\n            if (config.inputShape == null) {\n                throw new errors_1.ValueError('An InputLayer should be passed either a ' +\n                    '`batchInputShape` or an `inputShape`.');\n            }\n            else {\n                batchInputShape = [config.batchSize].concat(config.inputShape);\n            }\n        }\n        else {\n            if (config.batchSize != null) {\n                throw new errors_1.ValueError('Cannot specify batchSize if batchInputShape is' +\n                    'specified when creating an InputLayer.');\n            }\n        }\n        var dtype = config.dtype || K.floatx();\n        _this.batchInputShape = batchInputShape;\n        _this.dtype = dtype;\n        _this.inputSpec = [{ shape: batchInputShape }];\n        var inputTensor = new types_1.SymbolicTensor(_this.dtype, _this.batchInputShape, _this, [], {}, _this.name);\n        inputTensor.nodeIndex = 0;\n        inputTensor.tensorIndex = 0;\n        new Node({\n            outboundLayer: _this,\n            inboundLayers: [],\n            nodeIndices: [],\n            tensorIndices: [],\n            inputTensors: [inputTensor],\n            outputTensors: [inputTensor],\n            inputMasks: [null],\n            outputMasks: [null],\n            inputShapes: [batchInputShape],\n            outputShapes: [batchInputShape]\n        });\n        return _this;\n    }\n    InputLayer.prototype.apply = function (inputs, kwargs) {\n        throw new errors_1.ValueError('Cannot pass any input to an ' +\n            (\"InputLayer's apply() method. InputLayer name: \" + this.name));\n    };\n    InputLayer.prototype.getConfig = function () {\n        return {\n            batchInputShape: this.batchInputShape,\n            dtype: this.dtype,\n            sparse: this.sparse,\n            name: this.name\n        };\n    };\n    return InputLayer;\n}(Layer));\nexports.InputLayer = InputLayer;\ngeneric_utils.ClassNameMap.register('InputLayer', InputLayer);\nfunction Input(config) {\n    if (config.batchShape == null && config.shape == null) {\n        throw new Error('Please provide to Input either a `shape`' +\n            ' or a `batchShape` argument. Note that ' +\n            '`shape` does not include the batch ' +\n            'dimension.');\n    }\n    if (config.batchShape != null && config.shape != null) {\n        throw new errors_1.ValueError('Please provide either a `shape` or `batchShape` ' +\n            'argument to Input, but not both.');\n    }\n    var batchShape = config.batchShape;\n    if (config.shape != null && batchShape == null) {\n        batchShape = [null].concat(config.shape);\n    }\n    var dtype = config.dtype;\n    if (dtype == null) {\n        dtype = K.floatx();\n    }\n    var inputLayer = new InputLayer({\n        batchInputShape: batchShape,\n        name: config.name,\n        dtype: dtype,\n        sparse: config.sparse\n    });\n    var outputs = inputLayer.inboundNodes[0].outputTensors;\n    return outputs[0];\n}\nexports.Input = Input;\nvar Container = (function (_super) {\n    __extends(Container, _super);\n    function Container(config) {\n        var _this = _super.call(this, {}) || this;\n        _this.containerNodes = new Set();\n        _this.name = config.name;\n        if (_this.name == null) {\n            var prefix = _this.constructor.name.toLowerCase();\n            _this.name = K.getUid(prefix);\n        }\n        _this.supportsMasking = false;\n        _this.trainable = true;\n        _this.updatable = true;\n        if (Array.isArray(config.inputs)) {\n            _this.inputs = config.inputs.slice();\n        }\n        else {\n            _this.inputs = [config.inputs];\n        }\n        if (Array.isArray(config.outputs)) {\n            _this.outputs = config.outputs.slice();\n        }\n        else {\n            _this.outputs = [config.outputs];\n        }\n        if (_.uniq(_this.inputs).length !== _this.inputs.length) {\n            throw new errors_1.ValueError('The list of inputs passed to the model is ' +\n                'redundant. All inputs should only appear once. Found: ' +\n                _this.inputs.map(function (x) { return x.name; }));\n        }\n        if (_.uniq(_this.outputs).length !== _this.outputs.length) {\n            console.warn('The list of outputs passed to the model is redundant. ' +\n                'All outputs should only appear once. Found: ' +\n                _this.outputs.map(function (x) { return x.name; }));\n        }\n        _this.inputLayers = [];\n        _this.inputLayersNodeIndices = [];\n        _this.inputLayersTensorIndices = [];\n        _this.outputLayers = [];\n        _this.outputLayersNodeIndices = [];\n        _this.outputLayersTensorIndices = [];\n        _this.layers = [];\n        for (var _i = 0, _a = _this.outputs; _i < _a.length; _i++) {\n            var x = _a[_i];\n            var layer = x.sourceLayer;\n            var nodeIndex = x.nodeIndex;\n            var tensorIndex = x.tensorIndex;\n            _this.outputLayers.push(layer);\n            _this.outputLayersNodeIndices.push(nodeIndex);\n            _this.outputLayersTensorIndices.push(tensorIndex);\n        }\n        for (var _b = 0, _c = _this.inputs; _b < _c.length; _b++) {\n            var x = _c[_b];\n            var layer = x.sourceLayer;\n            var nodeIndex = x.nodeIndex;\n            var tensorIndex = x.tensorIndex;\n            generic_utils.assert(nodeIndex === 0, 'input layer has >1 nodes');\n            generic_utils.assert(tensorIndex === 0, 'input layer has >1 tensors');\n            _this.inputLayers.push(layer);\n            _this.inputLayersNodeIndices.push(nodeIndex);\n            _this.inputLayersTensorIndices.push(tensorIndex);\n        }\n        _this.inputNames = [];\n        _this.outputNames = [];\n        _this.feedInputShapes = [];\n        _this.feedInputNames = [];\n        _this.feedOutputNames = [];\n        for (var i = 0; i < _this.inputLayers.length; i++) {\n            var layer = _this.inputLayers[i];\n            if (!(layer instanceof InputLayer)) {\n                throw new TypeError('Input layers to a Model must be InputLayer objects. ' +\n                    (\"Received inputs: \" + config.inputs + \". \") +\n                    (\"Input \" + i + \" (0-based) originates \") +\n                    (\"from layer type \" + layer.constructor.name + \".\"));\n            }\n            _this.inputNames.push(layer.name);\n            _this.feedInputShapes.push(layer.batchInputShape);\n            _this.feedInputNames.push(layer.name);\n        }\n        for (var _d = 0, _e = _this.outputLayers; _d < _e.length; _d++) {\n            var layer = _e[_d];\n            _this.outputNames.push(layer.name);\n        }\n        _this.internalInputShapes = _this.inputs.map(function (x) { return x.shape; });\n        _this.internalOutputShapes = _this.outputs.map(function (x) { return x.shape; });\n        var nodesDepths = {};\n        var nodeIDToNode = {};\n        var layersDepths = {};\n        var layerIDToLayer = {};\n        var layerIndices = {};\n        var nodesInDecreasingDepth = [];\n        var buildMapOfGraph = function (tensor, finishedNodes, nodesInProgress, layer, nodeIndex, tensorIndex) {\n            if (layer == null || nodeIndex == null || tensorIndex == null) {\n                layer = tensor.sourceLayer;\n                nodeIndex = tensor.nodeIndex;\n                tensorIndex = tensor.tensorIndex;\n            }\n            var node = layer.inboundNodes[nodeIndex];\n            if (_.contains(nodesInProgress, node)) {\n                throw new errors_1.RuntimeError(\"The tensor \" + tensor.name + \" at layer \\\"\" + layer.name + \"\\\" \" +\n                    'is part of a cycle.');\n            }\n            if (_.contains(finishedNodes, node)) {\n                return;\n            }\n            _this.containerNodes.add(Container.nodeKey(layer, nodeIndex));\n            if (!(layer.id in layerIndices)) {\n                layerIndices[layer.id] = _.keys(layerIndices).length;\n            }\n            if (!_.contains(nodesInProgress, node)) {\n                nodesInProgress.push(node);\n            }\n            var numInboundLayers = node.inboundLayers.length;\n            for (var i = 0; i < numInboundLayers; i++) {\n                var x = node.inputTensors[i];\n                var layer_1 = node.inboundLayers[i];\n                var nodeIndex_1 = node.nodeIndices[i];\n                var tensorIndex_1 = node.tensorIndices[i];\n                buildMapOfGraph(x, finishedNodes, nodesInProgress, layer_1, nodeIndex_1, tensorIndex_1);\n            }\n            finishedNodes.push(node);\n            while (nodesInProgress.indexOf(node) >= 0) {\n                nodesInProgress.splice(nodesInProgress.indexOf(node), 1);\n            }\n            nodesInDecreasingDepth.push(node);\n        };\n        var finishedNodes = [];\n        var nodesInProgress = [];\n        for (var _f = 0, _g = _this.outputs; _f < _g.length; _f++) {\n            var x = _g[_f];\n            buildMapOfGraph(x, finishedNodes, nodesInProgress);\n        }\n        var reversedNodesInDecreasingDepth = nodesInDecreasingDepth.slice().reverse();\n        for (var _h = 0, reversedNodesInDecreasingDepth_1 = reversedNodesInDecreasingDepth; _h < reversedNodesInDecreasingDepth_1.length; _h++) {\n            var node = reversedNodesInDecreasingDepth_1[_h];\n            nodeIDToNode[node.id] = node;\n            if (!(node.id in nodesDepths)) {\n                nodesDepths[node.id] = 0;\n            }\n            var depth = nodesDepths[node.id];\n            var previousDepth = (layersDepths[node.outboundLayer.id] == null ?\n                0 :\n                layersDepths[node.outboundLayer.id]);\n            depth = Math.max(depth, previousDepth);\n            layersDepths[node.outboundLayer.id] = depth;\n            layerIDToLayer[node.outboundLayer.id] = node.outboundLayer;\n            nodesDepths[node.id] = depth;\n            for (var i = 0; i < node.inboundLayers.length; i++) {\n                var inboundLayer = node.inboundLayers[i];\n                var nodeIndex = node.nodeIndices[i];\n                var inboundNode = inboundLayer.inboundNodes[nodeIndex];\n                var previousDepth_1 = (nodesDepths[inboundNode.id] == null ? 0 :\n                    nodesDepths[inboundNode.id]);\n                nodesDepths[inboundNode.id] = Math.max(depth + 1, previousDepth_1);\n                nodeIDToNode[inboundNode.id] = inboundNode;\n            }\n        }\n        var nodesByDepth = {};\n        for (var _j = 0, _k = _.pairs(nodesDepths); _j < _k.length; _j++) {\n            var _l = _k[_j], nodeID = _l[0], depth = _l[1];\n            if (!(depth in nodesByDepth)) {\n                nodesByDepth[depth] = [];\n            }\n            nodesByDepth[depth].push(nodeIDToNode[nodeID]);\n        }\n        var layersByDepth = {};\n        for (var _m = 0, _o = _.pairs(layersDepths); _m < _o.length; _m++) {\n            var _p = _o[_m], layerID = _p[0], depth = _p[1];\n            if (!(depth in layersByDepth)) {\n                layersByDepth[depth] = [];\n            }\n            layersByDepth[depth].push(layerIDToLayer[layerID]);\n        }\n        var depthKeys = _.keys(layersByDepth)\n            .map(function (x) { return parseInt(x, 10); })\n            .sort(generic_utils.reverseNumberCompare);\n        _this.layers = [];\n        for (var _q = 0, depthKeys_1 = depthKeys; _q < depthKeys_1.length; _q++) {\n            var depth = depthKeys_1[_q];\n            var layersForDepth = layersByDepth[depth];\n            layersForDepth.sort(function (a, b) {\n                var aIndex = layerIndices[a.id];\n                var bIndex = layerIndices[b.id];\n                if (aIndex < bIndex) {\n                    return -1;\n                }\n                if (aIndex > bIndex) {\n                    return 1;\n                }\n                return 0;\n            });\n            for (var _r = 0, layersForDepth_1 = layersForDepth; _r < layersForDepth_1.length; _r++) {\n                var layer = layersForDepth_1[_r];\n                _this.layers.push(layer);\n            }\n        }\n        _this.layersByDepth = layersByDepth;\n        depthKeys = _.keys(nodesByDepth)\n            .map(function (x) { return parseInt(x, 10); })\n            .sort(generic_utils.reverseNumberCompare);\n        var computableTensors = _this.inputs.slice();\n        var layersWithCompleteInput = [];\n        for (var _s = 0, depthKeys_2 = depthKeys; _s < depthKeys_2.length; _s++) {\n            var depth = depthKeys_2[_s];\n            for (var _t = 0, _u = nodesByDepth[depth]; _t < _u.length; _t++) {\n                var node = _u[_t];\n                var layer = node.outboundLayer;\n                if (layer != null) {\n                    for (var _v = 0, _w = node.inputTensors; _v < _w.length; _v++) {\n                        var x = _w[_v];\n                        if (!_.contains(computableTensors, x)) {\n                            throw new errors_1.RuntimeError(\"Graph disconnected: cannot obtain value for tensor \" + x +\n                                (\" at layer \\\"\" + layer.name + \"\\\". \") +\n                                'The following previous layers were accessed without ' +\n                                (\"issue: \" + layersWithCompleteInput));\n                        }\n                    }\n                    for (var _x = 0, _y = node.outputTensors; _x < _y.length; _x++) {\n                        var x = _y[_x];\n                        computableTensors.push(x);\n                    }\n                    layersWithCompleteInput.push(layer.name);\n                }\n            }\n        }\n        _this.nodesByDepth = nodesByDepth;\n        var allNames = _this.layers.map(function (x) { return x.name; });\n        var _loop_1 = function (name_1) {\n            var numOccurrences = allNames.filter(function (x) { return x === name_1; }).length;\n            if (numOccurrences !== 1) {\n                throw new errors_1.RuntimeError(\"The name \\\"\" + name_1 + \"\\\" is used \" + numOccurrences + \" times \" +\n                    'in the model. All layer names should be unique. Layer names: ' +\n                    JSON.stringify(allNames));\n            }\n        };\n        for (var _z = 0, allNames_1 = allNames; _z < allNames_1.length; _z++) {\n            var name_1 = allNames_1[_z];\n            _loop_1(name_1);\n        }\n        _this.outboundNodes = [];\n        _this.inboundNodes = [];\n        new Node({\n            outboundLayer: _this,\n            inboundLayers: [],\n            nodeIndices: [],\n            tensorIndices: [],\n            inputTensors: _this.inputs,\n            outputTensors: _this.outputs,\n            inputMasks: _this.inputs.map(function (x) { return null; }),\n            outputMasks: _this.outputs.map(function (x) { return null; }),\n            inputShapes: _this.inputs.map(function (x) { return x.shape; }),\n            outputShapes: _this.outputs.map(function (x) { return x.shape; })\n        });\n        _this.built = true;\n        return _this;\n    }\n    Object.defineProperty(Container.prototype, \"trainableWeights\", {\n        get: function () {\n            if (this._trainableWeights.length > 0) {\n                throw new errors_1.ValueError('Container instance unexpectedly contains _trainableWeights.' +\n                    'The trainable weights of a Container are a union of the ' +\n                    'trainable weights of its consituent Layers. Its own ' +\n                    '_trainableWeights must remain an empty Array.');\n            }\n            if (!this.trainable) {\n                return [];\n            }\n            var weights = [];\n            for (var _i = 0, _a = this.layers; _i < _a.length; _i++) {\n                var layer = _a[_i];\n                weights = weights.concat(layer.trainableWeights);\n            }\n            return weights;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(Container.prototype, \"nonTrainableWeights\", {\n        get: function () {\n            var weights = [];\n            for (var _i = 0, _a = this.layers; _i < _a.length; _i++) {\n                var layer = _a[_i];\n                weights.push.apply(weights, layer.nonTrainableWeights);\n            }\n            if (!this.trainable) {\n                var trainableWeights = [];\n                for (var _b = 0, _c = this.layers; _b < _c.length; _b++) {\n                    var layer = _c[_b];\n                    trainableWeights.push.apply(trainableWeights, layer.trainableWeights);\n                }\n                return trainableWeights.concat(weights);\n            }\n            return weights;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Object.defineProperty(Container.prototype, \"weights\", {\n        get: function () {\n            return this.trainableWeights.concat(this.nonTrainableWeights);\n        },\n        enumerable: true,\n        configurable: true\n    });\n    Container.prototype.loadWeights = function (weightsJSON, skipMismatch, isNamedTensorMap) {\n        if (skipMismatch === void 0) { skipMismatch = false; }\n        if (isNamedTensorMap === void 0) { isNamedTensorMap = false; }\n        if (isNamedTensorMap) {\n            loadWeightsFromNamedTensorMap(weightsJSON, this.layers);\n        }\n        else {\n            loadWeightsFromJson(weightsJSON, this.layers, skipMismatch);\n        }\n    };\n    Container.prototype.updatedConfig = function () {\n        var theConfig = this.getConfig();\n        var modelConfig = {\n            className: this.constructor.name,\n            config: theConfig,\n            kerasVersion: 'tfjs-layers pre-release',\n            backend: 'TensorFlow.js'\n        };\n        return modelConfig;\n    };\n    Container.prototype.toJSON = function (unused) {\n        var modelConfig = this.updatedConfig();\n        return JSON.stringify(serialization_utils_1.convertTsToPythonic(modelConfig));\n    };\n    Container.prototype.call = function (inputs, kwargs) {\n        inputs = generic_utils.toList(inputs);\n        var masks;\n        if ('mask' in kwargs) {\n            masks = generic_utils.toList(kwargs['mask']);\n        }\n        else {\n            masks = generic_utils.pyListRepeat(null, inputs.length);\n        }\n        return this.runInternalGraph(inputs, masks)[0];\n    };\n    Container.prototype.computeMask = function (inputs, mask) {\n        inputs = generic_utils.toList(inputs);\n        var masks;\n        if (mask == null) {\n            masks = generic_utils.pyListRepeat(null, inputs.length);\n        }\n        else {\n            masks = generic_utils.toList(mask);\n        }\n        return this.runInternalGraph(inputs, masks)[1];\n    };\n    Container.prototype.computeOutputShape = function (inputShape) {\n        var inputShapes = generic_utils.normalizeShapeList(inputShape);\n        if (inputShapes.length !== this.inputLayers.length) {\n            throw new errors_1.ValueError(\"Invalid inputShape argument \" + inputShape + \": \" +\n                (\"model has \" + this.inputLayers.length + \" tensor inputs.\"));\n        }\n        var layersToOutputShapes = {};\n        for (var i = 0; i < inputShapes.length; i++) {\n            var layer = this.inputLayers[i];\n            var inputShape_1 = inputShapes[i];\n            var shapeKey = layer.name + '_0_0';\n            layersToOutputShapes[shapeKey] = inputShape_1;\n        }\n        var depthKeys = Object.keys(this.nodesByDepth)\n            .map(function (x) { return parseInt(x, 10); })\n            .sort(generic_utils.reverseNumberCompare);\n        if (depthKeys.length > 1) {\n            for (var _i = 0, depthKeys_3 = depthKeys; _i < depthKeys_3.length; _i++) {\n                var depth = depthKeys_3[_i];\n                var nodes = this.nodesByDepth[depth];\n                for (var _a = 0, nodes_1 = nodes; _a < nodes_1.length; _a++) {\n                    var node = nodes_1[_a];\n                    var layer = node.outboundLayer;\n                    if (_.contains(this.inputLayers.map(function (x) { return x.id; }), layer.id)) {\n                        continue;\n                    }\n                    var inputShapes_1 = [];\n                    for (var j = 0; j < node.inboundLayers.length; j++) {\n                        var inboundLayer = node.inboundLayers[j];\n                        var nodeIndex_2 = node.nodeIndices[j];\n                        var tensorIndex = node.tensorIndices[j];\n                        var shapeKey = inboundLayer.name + \"_\" + nodeIndex_2 + \"_\" + tensorIndex;\n                        var inputShape_2 = layersToOutputShapes[shapeKey];\n                        inputShapes_1.push(inputShape_2);\n                    }\n                    var outputShape = layer.computeOutputShape(generic_utils.singletonOrArray(inputShapes_1));\n                    var outputShapes_1 = generic_utils.normalizeShapeList(outputShape);\n                    var nodeIndex = layer.inboundNodes.indexOf(node);\n                    for (var j = 0; j < outputShapes_1.length; j++) {\n                        var shapeKey = layer.name + \"_\" + nodeIndex + \"_\" + j;\n                        layersToOutputShapes[shapeKey] = outputShapes_1[j];\n                    }\n                }\n            }\n        }\n        var outputShapes = [];\n        var outputShapeKeys = [];\n        for (var i = 0; i < this.outputLayers.length; i++) {\n            var layer = this.outputLayers[i];\n            var nodeIndex = this.outputLayersNodeIndices[i];\n            var tensorIndex = this.outputLayersTensorIndices[i];\n            var shapeKey = layer.name + \"_\" + nodeIndex + \"_\" + tensorIndex;\n            outputShapeKeys.push(shapeKey);\n        }\n        for (var i = 0; i < outputShapeKeys.length; i++) {\n            var key = outputShapeKeys[i];\n            generic_utils.assert(key in layersToOutputShapes);\n            outputShapes.push(layersToOutputShapes[key]);\n        }\n        return generic_utils.singletonOrArray(outputShapes);\n    };\n    Container.prototype.runInternalGraph = function (inputs, masks) {\n        if (masks == null) {\n            masks = generic_utils.pyListRepeat(null, inputs.length);\n        }\n        var tensorMap = {};\n        for (var _i = 0, _a = _.zip(this.inputs, inputs, masks); _i < _a.length; _i++) {\n            var _b = _a[_i], x = _b[0], y = _b[1], mask = _b[2];\n            tensorMap[x.id] = [y, mask];\n        }\n        var depthKeys = Object.keys(this.nodesByDepth)\n            .map(function (x) { return parseInt(x, 10); })\n            .sort(generic_utils.reverseNumberCompare);\n        for (var _c = 0, depthKeys_4 = depthKeys; _c < depthKeys_4.length; _c++) {\n            var depth = depthKeys_4[_c];\n            var nodes = this.nodesByDepth[depth];\n            for (var _d = 0, nodes_2 = nodes; _d < nodes_2.length; _d++) {\n                var node = nodes_2[_d];\n                var layer = node.outboundLayer;\n                var referenceInputTensors = node.inputTensors;\n                var referenceOutputTensors = node.outputTensors;\n                var computedData = new Array();\n                for (var _e = 0, referenceInputTensors_1 = referenceInputTensors; _e < referenceInputTensors_1.length; _e++) {\n                    var x = referenceInputTensors_1[_e];\n                    if (x.id in tensorMap) {\n                        computedData.push(tensorMap[x.id]);\n                    }\n                }\n                if (computedData.length === referenceInputTensors.length) {\n                    var kwargs = {};\n                    var computedTensors = void 0;\n                    var computedMasks = void 0;\n                    var outputTensors_1 = void 0;\n                    var outputMasks_1 = void 0;\n                    if (node.callArgs != null) {\n                        kwargs = node.callArgs;\n                    }\n                    if (computedData.length === 1) {\n                        var _f = computedData[0], computedTensor = _f[0], computedMask = _f[1];\n                        if (kwargs.mask == null) {\n                            kwargs['mask'] = computedMask;\n                        }\n                        outputTensors_1 =\n                            generic_utils.toList(layer.call(computedTensor, kwargs));\n                        outputMasks_1 = generic_utils.toList(layer.computeMask(computedTensor, computedMask));\n                        computedTensors = [computedTensor];\n                        computedMasks = [computedMask];\n                    }\n                    else {\n                        computedTensors = computedData.map(function (x) { return x[0]; });\n                        computedMasks = computedData.map(function (x) { return x[1]; });\n                        if (kwargs.mask == null) {\n                            kwargs['mask'] = computedMasks;\n                        }\n                        outputTensors_1 =\n                            generic_utils.toList(layer.call(computedTensors, kwargs));\n                        outputMasks_1 = generic_utils.toList(layer.computeMask(computedTensors, computedMasks));\n                    }\n                    if (layer.activityRegularizer) {\n                        throw new errors_1.NotImplementedError('Model invocation with concrete Tensor value(s) in the ' +\n                            'presence of activity regularizer(s) is not supported yet.');\n                    }\n                    for (var _g = 0, _h = _.zip(referenceOutputTensors, outputTensors_1, outputMasks_1); _g < _h.length; _g++) {\n                        var _j = _h[_g], x = _j[0], y = _j[1], mask = _j[2];\n                        tensorMap[x.id] = [y, mask];\n                    }\n                }\n            }\n        }\n        var outputTensors = [];\n        var outputMasks = [];\n        var outputShapes = [];\n        for (var _k = 0, _l = this.outputs; _k < _l.length; _k++) {\n            var x = _l[_k];\n            generic_utils.assert(x.id in tensorMap, \"Could not compute output \" + x.name + \" : \" + x.id);\n            var _m = tensorMap[x.id], tensor = _m[0], mask = _m[1];\n            outputShapes.push(tensor.shape);\n            outputTensors.push(tensor);\n            outputMasks.push(mask);\n        }\n        return [outputTensors, outputMasks, outputShapes];\n    };\n    Container.prototype.buildNodeConversionMap = function (layers) {\n        var nodeConversionMap = {};\n        var keptNodes;\n        for (var _i = 0, _a = this.layers; _i < _a.length; _i++) {\n            var layer = _a[_i];\n            keptNodes = layer instanceof Container ? 1 : 0;\n            for (var originalNodeIndex = 0; originalNodeIndex < layer.inboundNodes.length; originalNodeIndex++) {\n                var nodeKey = Container.nodeKey(layer, originalNodeIndex);\n                if (nodeKey in this.containerNodes) {\n                    nodeConversionMap[nodeKey] = keptNodes;\n                    keptNodes += 1;\n                }\n            }\n        }\n        return nodeConversionMap;\n    };\n    Container.prototype.getLayer = function (name, index) {\n        if (index != null) {\n            if (this.layers.length <= index) {\n                throw new errors_1.ValueError(\"Was asked to retrieve layer at index \" + index + \", but model only \" +\n                    (\"has \" + this.layers.length + \" layer(s).\"));\n            }\n            else {\n                return this.layers[index];\n            }\n        }\n        else {\n            if (name == null) {\n                throw new errors_1.ValueError('Provide either a layer name or layer index');\n            }\n        }\n        for (var _i = 0, _a = this.layers; _i < _a.length; _i++) {\n            var layer = _a[_i];\n            if (layer.name === name) {\n                return layer;\n            }\n        }\n        throw new errors_1.ValueError(\"No such layer: \" + name);\n    };\n    Container.prototype.calculateLosses = function () {\n        var _this = this;\n        return tfjs_core_1.tidy(function () {\n            var losses = [];\n            for (var _i = 0, _a = _this.layers; _i < _a.length; _i++) {\n                var layer = _a[_i];\n                for (var nodeIndex = 0; nodeIndex < layer.inboundNodes.length; ++nodeIndex) {\n                    var nodeKey = Container.nodeKey(layer, nodeIndex);\n                    if (_this.containerNodes.has(nodeKey)) {\n                        losses.push.apply(losses, layer.calculateLosses());\n                    }\n                }\n            }\n            return losses;\n        });\n    };\n    Container.prototype.getConfig = function () {\n        var config = { name: this.name };\n        var nodeConversionMap = this.buildNodeConversionMap(this.layers);\n        var layerConfigs = [];\n        for (var _i = 0, _a = this.layers; _i < _a.length; _i++) {\n            var layer = _a[_i];\n            var layerClassName = layer.constructor.name;\n            var layerConfig = layer.getConfig();\n            var filteredInboundNodes = [];\n            for (var originalNodeIndex = 0; originalNodeIndex < layer.inboundNodes.length; originalNodeIndex++) {\n                var node = layer.inboundNodes[originalNodeIndex];\n                var nodeKey = Container.nodeKey(layer, originalNodeIndex);\n                var kwargs = {};\n                if (this.containerNodes.has(nodeKey)) {\n                    if (node.callArgs) {\n                        var testString = JSON.stringify(node.callArgs);\n                        if (testString.indexOf('undefined') === -1) {\n                            kwargs = node.callArgs;\n                        }\n                        else {\n                            console.warn(\"Layer \" + layer.name + \" was passed \" +\n                                \"non-serializable keyword arguments: \" +\n                                (node.callArgs + \". They will not be included \") +\n                                \"in the serialized model (and thus will be \" +\n                                \"missing at deserialization time).\");\n                            kwargs = {};\n                        }\n                    }\n                    if (node.inboundLayers.length > 0) {\n                        var nodeData = [];\n                        for (var i = 0; i < node.inboundLayers.length; i++) {\n                            var inboundLayer = node.inboundLayers[i];\n                            var nodeIndex = node.nodeIndices[i];\n                            var tensorIndex = node.tensorIndices[i];\n                            var nodeKey_1 = Container.nodeKey(inboundLayer, nodeIndex);\n                            var newNodeIndex = nodeConversionMap[nodeKey_1];\n                            if (newNodeIndex === null || newNodeIndex === undefined) {\n                                newNodeIndex = 0;\n                            }\n                            nodeData.push([inboundLayer.name, newNodeIndex, tensorIndex, kwargs]);\n                        }\n                        filteredInboundNodes.push(nodeData);\n                    }\n                }\n            }\n            layerConfigs.push({\n                name: layer.name,\n                className: layerClassName,\n                config: layerConfig,\n                inboundNodes: filteredInboundNodes\n            });\n        }\n        config['layers'] = layerConfigs;\n        var modelInputs = [];\n        for (var i = 0; i < this.inputLayers.length; i++) {\n            var layer = this.inputLayers[i];\n            var nodeIndex = this.inputLayersNodeIndices[i];\n            var nodeKey = Container.nodeKey(layer, nodeIndex);\n            if (!this.containerNodes.has(nodeKey)) {\n                continue;\n            }\n            var newNodeIndex = nodeConversionMap[nodeKey];\n            if (newNodeIndex === null || newNodeIndex === undefined) {\n                newNodeIndex = 0;\n            }\n            var tensorIndex = this.inputLayersTensorIndices[i];\n            modelInputs.push([layer.name, newNodeIndex, tensorIndex]);\n        }\n        config['inputLayers'] = modelInputs;\n        var modelOutputs = [];\n        for (var i = 0; i < this.outputLayers.length; i++) {\n            var layer = this.outputLayers[i];\n            var nodeIndex = this.outputLayersNodeIndices[i];\n            var nodeKey = Container.nodeKey(layer, nodeIndex);\n            if (!this.containerNodes.has(nodeKey)) {\n                continue;\n            }\n            var newNodeIndex = nodeConversionMap[nodeKey];\n            if (newNodeIndex === null || newNodeIndex === undefined) {\n                newNodeIndex = 0;\n            }\n            var tensorIndex = this.outputLayersTensorIndices[i];\n            modelOutputs.push([layer.name, newNodeIndex, tensorIndex]);\n        }\n        config['outputLayers'] = modelOutputs;\n        return config;\n    };\n    Container.fromConfig = function (cls, config) {\n        var createdLayers = {};\n        var unprocessedNodes = {};\n        function addUnprocessedNode(layer, nodeData) {\n            if (!(layer.name in unprocessedNodes)) {\n                unprocessedNodes[layer.name] = [nodeData];\n            }\n            else {\n                unprocessedNodes[layer.name].push(nodeData);\n            }\n        }\n        function processNode(layer, nodeData) {\n            var inputTensors = [];\n            var kwargs;\n            for (var _i = 0, nodeData_1 = nodeData; _i < nodeData_1.length; _i++) {\n                var inputData = nodeData_1[_i];\n                var inboundLayerName = inputData[0];\n                var inboundNodeIndex = inputData[1];\n                var inboundTensorIndex = inputData[2];\n                if (inputData.length === 3) {\n                    kwargs = {};\n                }\n                else if (inputData.length === 4) {\n                    kwargs = inputData[3];\n                }\n                else {\n                    throw new errors_1.ValueError(\"Improperly formatted model config for layer \" + JSON.stringify(layer) + \": \" + JSON.stringify(inputData));\n                }\n                if (!(inboundLayerName in createdLayers)) {\n                    addUnprocessedNode(layer, nodeData);\n                    return;\n                }\n                var inboundLayer = createdLayers[inboundLayerName];\n                if (inboundLayer.inboundNodes.length <= inboundNodeIndex) {\n                    addUnprocessedNode(layer, nodeData);\n                    return;\n                }\n                var inboundNode = inboundLayer.inboundNodes[inboundNodeIndex];\n                inputTensors.push(inboundNode.outputTensors[inboundTensorIndex]);\n            }\n            if (!_.isEmpty(inputTensors)) {\n                layer.apply(generic_utils.singletonOrArray(inputTensors), kwargs);\n            }\n        }\n        function processLayer(layerData) {\n            var layerName = layerData.name;\n            var layer = serialization_1.deserialize(layerData, config.customObjects != null ? config.customObjects :\n                {});\n            createdLayers[layerName] = layer;\n            var inboundNodesData = layerData.inboundNodes;\n            for (var _i = 0, inboundNodesData_1 = inboundNodesData; _i < inboundNodesData_1.length; _i++) {\n                var nodeData = inboundNodesData_1[_i];\n                if (!(nodeData instanceof Array)) {\n                    throw new errors_1.ValueError(\"Corrupted configuration, expected array for nodeData: \" + nodeData);\n                }\n                addUnprocessedNode(layer, nodeData);\n            }\n        }\n        var name = config.name;\n        var layersFromConfig = config.layers;\n        for (var _i = 0, layersFromConfig_1 = layersFromConfig; _i < layersFromConfig_1.length; _i++) {\n            var layerData = layersFromConfig_1[_i];\n            processLayer(layerData);\n        }\n        while (!_.isEmpty(unprocessedNodes)) {\n            for (var _a = 0, layersFromConfig_2 = layersFromConfig; _a < layersFromConfig_2.length; _a++) {\n                var layerData = layersFromConfig_2[_a];\n                var layer = createdLayers[layerData.name];\n                if (layer.name in unprocessedNodes) {\n                    for (var _b = 0, _c = unprocessedNodes[layer.name]; _b < _c.length; _b++) {\n                        var nodeData = _c[_b];\n                        processNode(layer, nodeData);\n                    }\n                    delete unprocessedNodes[layer.name];\n                }\n            }\n        }\n        var inputTensors = [];\n        var outputTensors = [];\n        var inputLayersFromConfig = config.inputLayers;\n        for (var _d = 0, inputLayersFromConfig_1 = inputLayersFromConfig; _d < inputLayersFromConfig_1.length; _d++) {\n            var layerData = inputLayersFromConfig_1[_d];\n            var layerName = layerData[0];\n            var nodeIndex = layerData[1];\n            var tensorIndex = layerData[2];\n            generic_utils.assert(layerName in createdLayers);\n            var layer = createdLayers[layerName];\n            var layerOutputTensors = layer.inboundNodes[nodeIndex].outputTensors;\n            inputTensors.push(layerOutputTensors[tensorIndex]);\n        }\n        var outputLayersFromConfig = config.outputLayers;\n        for (var _e = 0, outputLayersFromConfig_1 = outputLayersFromConfig; _e < outputLayersFromConfig_1.length; _e++) {\n            var layerData = outputLayersFromConfig_1[_e];\n            var layerName = layerData[0];\n            var nodeIndex = layerData[1];\n            var tensorIndex = layerData[2];\n            generic_utils.assert(layerName in createdLayers);\n            var layer = createdLayers[layerName];\n            var layerOutputTensors = layer.inboundNodes[nodeIndex].outputTensors;\n            outputTensors.push(layerOutputTensors[tensorIndex]);\n        }\n        return new cls({ inputs: inputTensors, outputs: outputTensors, name: name });\n    };\n    Object.defineProperty(Container.prototype, \"stateful\", {\n        get: function () {\n            if (this._stateful) {\n                throw new errors_1.ValueError('Container instance unexpectedly has _stateful = true. The ' +\n                    'statefulness of a Container is determined by the Layers it ' +\n                    'contains. Its _stateful property must remain the default false.');\n            }\n            for (var _i = 0, _a = this.layers; _i < _a.length; _i++) {\n                var layer = _a[_i];\n                if (layer.stateful) {\n                    return true;\n                }\n            }\n            return false;\n        },\n        enumerable: true,\n        configurable: true\n    });\n    return Container;\n}(Layer));\nexports.Container = Container;\nfunction getSourceInputs(tensor, layer, nodeIndex) {\n    if (layer == null || (nodeIndex != null && nodeIndex > 0)) {\n        layer = tensor.sourceLayer;\n        nodeIndex = tensor.nodeIndex;\n    }\n    if (layer.inboundNodes.length === 0) {\n        return [tensor];\n    }\n    else {\n        var node = layer.inboundNodes[nodeIndex];\n        if (node.inboundLayers.length === 0) {\n            return node.inputTensors;\n        }\n        else {\n            var sourceTensors = [];\n            for (var i = 0; i < node.inboundLayers.length; i++) {\n                var x = node.inputTensors[i];\n                var layer_2 = node.inboundLayers[i];\n                var nodeIndex_3 = node.nodeIndices[i];\n                var previousSources = getSourceInputs(x, layer_2, nodeIndex_3);\n                for (var _i = 0, previousSources_1 = previousSources; _i < previousSources_1.length; _i++) {\n                    var x_1 = previousSources_1[_i];\n                    if (!_.contains(sourceTensors, x_1)) {\n                        sourceTensors.push(x_1);\n                    }\n                }\n            }\n            return sourceTensors;\n        }\n    }\n}\nexports.getSourceInputs = getSourceInputs;\nfunction loadTensor(dtype, shape, value) {\n    var dataType = generic_utils.stringToDType(dtype);\n    return tfjs_core_1.Tensor.make(shape, { values: shape.length === 0 ? value : _.flatten(value) }, dataType);\n}\nfunction preprocessWeightsForLoading(layer, weights, originalKerasVersion, originalBackend) {\n    if (!originalKerasVersion.startsWith('2.')) {\n        throw new errors_1.ValueError('Unsupported Keras version in weights being loaded: ' +\n            originalKerasVersion);\n    }\n    return weights;\n}\nfunction loadWeightsFromNamedTensorMap(weights, layers) {\n    var nameToWeight = {};\n    var totalWeightsCount = 0;\n    for (var _i = 0, layers_1 = layers; _i < layers_1.length; _i++) {\n        var layer = layers_1[_i];\n        for (var _a = 0, _b = layer.weights; _a < _b.length; _a++) {\n            var weight = _b[_a];\n            if (nameToWeight[weight.name] != null) {\n                throw new errors_1.ValueError(\"Duplicate weight name: \" + weight.name);\n            }\n            nameToWeight[weight.name] = weight;\n            totalWeightsCount++;\n        }\n    }\n    var weightValueTuples = [];\n    for (var name_2 in weights) {\n        weightValueTuples.push([nameToWeight[name_2], weights[name_2]]);\n        delete nameToWeight[name_2];\n    }\n    var unsetNames = [];\n    for (var name_3 in nameToWeight) {\n        unsetNames.push(name_3);\n    }\n    if (unsetNames.length > 0) {\n        throw new errors_1.ValueError(unsetNames.length + \" of \" + totalWeightsCount + \" weights are not set: \" +\n            (\"\" + unsetNames));\n    }\n    K.batchSetValue(weightValueTuples);\n}\nexports.loadWeightsFromNamedTensorMap = loadWeightsFromNamedTensorMap;\nfunction loadWeightsFromJson(weightsJSON, layers, skipMismatch) {\n    if (skipMismatch === void 0) { skipMismatch = false; }\n    var originalKerasVersion = weightsJSON['keras_version'];\n    var originalBackend = weightsJSON['backend'];\n    var layerNames = layers.map(function (layer) { return layer.name; });\n    var index = {};\n    for (var _i = 0, layers_2 = layers; _i < layers_2.length; _i++) {\n        var layer = layers_2[_i];\n        if (layer.name != null) {\n            if (index[layer.name] == null) {\n                index[layer.name] = [];\n            }\n            index[layer.name].push(layer);\n        }\n    }\n    var nameToWeights = weightsJSON['weights'];\n    var weightValueTuples = [];\n    for (var k = 0; k < layerNames.length; ++k) {\n        var name_4 = layerNames[k];\n        var layerWeights = nameToWeights[name_4];\n        if (layerWeights == null) {\n            layerWeights = [];\n        }\n        var weightValues = [];\n        for (var n = 0; n < layerWeights.length; ++n) {\n            var weightEntry = layerWeights[n];\n            weightValues.push(new types_1.LayerVariable(loadTensor(weightEntry['dtype'], weightEntry['shape'], weightEntry['value'])));\n        }\n        for (var _a = 0, _b = index[name_4]; _a < _b.length; _a++) {\n            var layer = _b[_a];\n            var symbolicWeights = layer.weights;\n            weightValues = preprocessWeightsForLoading(layer, weightValues, originalKerasVersion, originalBackend);\n            if (weightValues.length !== symbolicWeights.length) {\n                if (skipMismatch) {\n                    console.warn(\"Skipping loading of weights of layer \" + layer.name + \" \" +\n                        (\"due to mismatch in number of weights: (\" + weightValues.length + \" \") +\n                        (\"vs \" + symbolicWeights.length + \").\"));\n                }\n                else {\n                    throw new errors_1.ValueError(\"Layer #\" + k + \" (named \\\"\" + layer.name + \"\\\") expects \" +\n                        (symbolicWeights.length + \" weight(s), but the saved weights \") +\n                        (\"have \" + weightValues.length + \" element(s).\"));\n                }\n            }\n            for (var i = 0; i < weightValues.length; ++i) {\n                if (skipMismatch) {\n                    if (!_.isEqual(symbolicWeights[i].shape, weightValues[i].shape)) {\n                        console.warn(\"Skipping loading of weights for layer \" + layer.name + \" due \" +\n                            (\"to mismatch in shape (\" + symbolicWeights[i].shape + \" vs \") +\n                            (weightValues[i].shape + \")\"));\n                        continue;\n                    }\n                }\n                weightValueTuples.push([symbolicWeights[i], weightValues[i].read()]);\n            }\n        }\n    }\n    K.batchSetValue(weightValueTuples);\n}\nexports.loadWeightsFromJson = loadWeightsFromJson;\n"},"hash":"be6e9f3364d2dc586152c3b5723a0205","cacheData":{"env":{}}}